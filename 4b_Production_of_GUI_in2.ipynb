{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pandas import Series\n",
    "from pandas import DataFrame\n",
    "\n",
    "from scipy.stats import poisson\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "downweight_granularity=['FltNum','dtime','Direction','dday','month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data=pd.read_csv('~/Data/Intermediate_Output/R_Output_Test_Pax.csv',sep=',')\n",
    "Data=pd.read_csv('R_Output_Test_Pax.csv',sep=',')\n",
    "Data=Data[['DepDate','FltNum','yday','dtime','Direction','month','dday','Dprio','NumPax']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Map_Dates=DataFrame([Data['DepDate'].unique().tolist(),[pd.to_datetime(x) for x in Data['DepDate'].unique().tolist()]]).transpose()\n",
    "Map_Dates.columns=['DepDate','DepDate_dt']\n",
    "Map_Dates['DepDate']=Map_Dates['DepDate'].astype('str')\n",
    "\n",
    "Data=Data.merge(Map_Dates,on=['DepDate'])\n",
    "Data['DepDate']=Data['DepDate_dt']\n",
    "Data=Data[[x for x in Data.columns if x!='DepDate_dt']]\n",
    "\n",
    "Data['TicketDate']=Data['DepDate']-Data['Dprio'].apply(lambda x: datetime.timedelta(x))\n",
    "\n",
    "Data=Data.loc[Data['TicketDate']<=pd.to_datetime(datetime.datetime.today().strftime('%Y-%m-%d')),:]\n",
    "\n",
    "Data=Data[[x for x in Data.columns if x!='TicketDate']]\n",
    "\n",
    "Data['Dprio']=-Data['Dprio']\n",
    "Data=Data.set_index(['DepDate','FltNum','yday','dtime','Direction','month','dday','Dprio'])\n",
    "Data=Data.groupby(level=[0,1,2,3,4,5,6,7]).sum().groupby(level=[0,1,2,3,4,5,6])['NumPax'].cumsum().reset_index()\n",
    "\n",
    "Data['Dprio']=-Data['Dprio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Probability=pd.read_csv('~/Data/Intermediate_Output/Probability.csv')\n",
    "Probability=pd.read_csv('Probability.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data=Data.merge(Probability,on=['Dprio']+downweight_granularity)\n",
    "Data['SpoilageRisk']=poisson.cdf(Data['Cap_downweighted']-Data['NumPax'],Data['Ideal_intermediate_downweighted'])\n",
    "Data['SpillageRisk']=1-poisson.cdf(Data['Cap_full']-Data['NumPax'],Data['Ideal_intermediate_full'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data['Intensity_full']=Data['NumPax']-Data['Ideal_average_full']\n",
    "Data['Intensity_downweighted']=Data['NumPax']-Data['Ideal_average_downweighted']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "deptime=[str(x/60).split('.')[0]+':'+str(round(float('0.'+str(x/60).split('.')[1])*60)) for x in Data['dtime'].unique()]\n",
    "deptime=[x+'0' if len(x.split(':')[1])==1 else x for x in deptime]\n",
    "deptime=['0'+x if len(x.split(':')[0])==1 else x for x in deptime]\n",
    "\n",
    "Map_DepTime=DataFrame([Data['dtime'].unique(),[x+'0' if len(x.split(':')[1])==1 else x for x in deptime]]).transpose()\n",
    "Map_DepTime.columns=['dtime','deptime']\n",
    "Map_DepTime['dtime']=Map_DepTime['dtime'].astype('int')\n",
    "\n",
    "Data=Data.merge(Map_DepTime,on='dtime')\n",
    "\n",
    "Data['dtime']=Data['deptime']\n",
    "Data=Data[[x for x in Data.columns if x!='deptime']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data['SpoilageRisk']=Data['SpoilageRisk'].apply(lambda x: round(x,3))\n",
    "Data['SpillageRisk']=Data['SpillageRisk'].apply(lambda x: round(x,3))\n",
    "Data['Intensity_full']=Data['Intensity_full'].apply(lambda x: round(x,3))\n",
    "Data['Intensity_downweighted']=Data['Intensity_downweighted'].apply(lambda x: round(x,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data[['DepDate',\n",
    "# 'FltNum',\n",
    "# 'yday',\n",
    "# 'dtime',\n",
    "# 'Direction',\n",
    "# 'month',\n",
    "# 'dday',\n",
    "# 'Dprio',\n",
    "# 'NumPax',\n",
    "# 'Cap_full',\n",
    "# 'Cap_downweighted',\n",
    "# 'Ideal_average_full',\n",
    "# 'Ideal_average_downweighted',\n",
    "# 'SpoilageRisk',\n",
    "# 'SpillageRisk',\n",
    "# 'Intensity_full',\n",
    "# 'Intensity_downweighted']].to_csv('~/Data/FrontEnd_Input/GUI_in2.csv',index=False)\n",
    "\n",
    "Data[['DepDate',\n",
    "'FltNum',\n",
    "'yday',\n",
    "'dtime',\n",
    "'Direction',\n",
    "'month',\n",
    "'dday',\n",
    "'Dprio',\n",
    "'NumPax',\n",
    "'Cap_full',\n",
    "'Cap_downweighted',\n",
    "'Ideal_average_full',\n",
    "'Ideal_average_downweighted',\n",
    "'SpoilageRisk',\n",
    "'SpillageRisk',\n",
    "'Intensity_full',\n",
    "'Intensity_downweighted']].to_csv('GUI_in2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
