{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "import dash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Input, Output, State\n",
    "import dash_table\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "import plotly.plotly as py\n",
    "import plotly.figure_factory as ff\n",
    "\n",
    "import flask\n",
    "from flask_cors import CORS\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series\n",
    "from pandas import DataFrame\n",
    "\n",
    "import os\n",
    "from os import environ\n",
    "import requests\n",
    "import io\n",
    "\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "import socket\n",
    "\n",
    "import seaborn as sns\n",
    "from itertools import groupby"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_groups(sequence):\n",
    "    count_cuts=0\n",
    "    local_groups=[]\n",
    "    for (key,group) in groupby(sequence): \n",
    "        count_cuts=count_cuts+1\n",
    "        local_groups=local_groups+[count_cuts]*len(list(group))\n",
    "    return local_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def breakgroups(sequence):\n",
    "    group=[]\n",
    "    count=0\n",
    "    for i in range(len(sequence)-1):\n",
    "        if sequence[i]!=sequence[i+1]:\n",
    "            count=count+1\n",
    "            group.append(count)\n",
    "        else:\n",
    "            group.append(0)\n",
    "    return [x for x in zip(group+[0],[0]+group)]\n",
    "    return group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyst = environ['analyst']\n",
    "#analyst='testing'\n",
    "path='/home/ubuntu/Data/'\n",
    "#path='C:/Users/35266/Documents/Python Scripts/el/'\n",
    "port={'pierrick': 3999, 'nancy': 4000, 'patrick': 4001, 'testing': 3998}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_Risk=[x for x in os.listdir(path+'FrontEnd_Input_'+analyst+'/') if 'Risk' in x]\n",
    "Risk=pd.read_csv(path+'FrontEnd_Input_'+analyst+'/'+files_Risk[0])\n",
    "for f in files_Risk[1:]:\n",
    "    Intermediate=pd.read_csv(path+'FrontEnd_Input_'+analyst+'/'+f)\n",
    "    Risk=pd.concat([Risk,Intermediate])\n",
    "Risk['Route']=Risk['Route'].astype('str')\n",
    "Risk['DepDate']=Risk['DepDate'].astype('str')    \n",
    "Risk['FltNum']=Risk['FltNum'].astype('str')\n",
    "Risk['dtime']=Risk['dtime'].astype('str')\n",
    "\n",
    "files_IdealCurve=[x for x in os.listdir(path+'FrontEnd_Input_'+analyst+'/') if 'IdealCurve' in x]\n",
    "IdealCurve=pd.read_csv(path+'FrontEnd_Input_'+analyst+'/'+files_IdealCurve[0])\n",
    "for f in files_IdealCurve[1:]:\n",
    "    Intermediate=pd.read_csv(path+'FrontEnd_Input_'+analyst+'/'+f)\n",
    "    IdealCurve=pd.concat([IdealCurve,Intermediate])\n",
    "IdealCurve['Route']=IdealCurve['Route'].astype('str')\n",
    "IdealCurve['DepDate']=IdealCurve['DepDate'].astype('str')    \n",
    "IdealCurve['FltNum']=IdealCurve['FltNum'].astype('str')\n",
    "IdealCurve['dtime']=IdealCurve['dtime'].astype('str')\n",
    "    \n",
    "files_Actuals=[x for x in os.listdir(path+'FrontEnd_Input_'+analyst+'/') if 'Actuals' in x]\n",
    "Actuals=pd.read_csv(path+'FrontEnd_Input_'+analyst+'/'+files_Actuals[0])\n",
    "for f in files_Actuals[1:]:\n",
    "    Intermediate=pd.read_csv(path+'FrontEnd_Input_'+analyst+'/'+f)\n",
    "    Actuals=pd.concat([Actuals,Intermediate])\n",
    "Actuals['Route']=Actuals['Route'].astype('str')\n",
    "Actuals['DepDate']=Actuals['DepDate'].astype('str')    \n",
    "Actuals['FltNum']=Actuals['FltNum'].astype('str')\n",
    "Actuals['dtime']=Actuals['dtime'].astype('str')\n",
    "    \n",
    "files_Capacity=[x for x in os.listdir(path+'FrontEnd_Input_'+analyst+'/') if 'Capacity' in x]\n",
    "Capacity=pd.read_csv(path+'FrontEnd_Input_'+analyst+'/'+files_Capacity[0])\n",
    "for f in files_Capacity[1:]:\n",
    "    Intermediate=pd.read_csv(path+'FrontEnd_Input_'+analyst+'/'+f)\n",
    "    Capacity=pd.concat([Capacity,Intermediate])\n",
    "Capacity['Route']=Capacity['Route'].astype('str')\n",
    "Capacity['DepDate']=Capacity['DepDate'].astype('str')    \n",
    "Capacity['FltNum']=Capacity['FltNum'].astype('str')\n",
    "Capacity['dtime']=Capacity['dtime'].astype('str')\n",
    "\n",
    "files_GroupPax=[x for x in os.listdir(path+'FrontEnd_Input_'+analyst+'/') if 'GroupPax' in x]\n",
    "GroupPax=pd.read_csv(path+'FrontEnd_Input_'+analyst+'/'+files_GroupPax[0])\n",
    "for f in files_GroupPax[1:]:\n",
    "    Intermediate=pd.read_csv(path+'FrontEnd_Input_'+analyst+'/'+f)\n",
    "    GroupPax=pd.concat([GroupPax,Intermediate])\n",
    "GroupPax['Route']=GroupPax['Route'].astype('str')\n",
    "GroupPax['DepDate']=GroupPax['DepDate'].astype('str')    \n",
    "GroupPax['FltNum']=GroupPax['FltNum'].astype('str')\n",
    "GroupPax['dtime']=GroupPax['dtime'].astype('str')\n",
    "\n",
    "GroupPax=GroupPax.rename(columns={'Group_pax_cumul': 'Group Pax'})\n",
    "\n",
    "files_LACeco=[x for x in os.listdir(path+'FrontEnd_Input_'+analyst+'/') if 'LAC' in x and 'eco' in x]\n",
    "LACeco=pd.read_csv(path+'FrontEnd_Input_'+analyst+'/'+files_LACeco[0])\n",
    "for f in files_LACeco[1:]:\n",
    "    Intermediate=pd.read_csv(path+'FrontEnd_Input_'+analyst+'/'+f)\n",
    "    LACeco=pd.concat([LACeco,Intermediate])\n",
    "LACeco['Route']=LACeco['Route'].astype('str')\n",
    "LACeco['DepDate']=LACeco['DepDate'].astype('str')    \n",
    "LACeco['FltNum']=LACeco['FltNum'].astype('str')\n",
    "LACeco['dtime']=LACeco['dtime'].astype('str')\n",
    "\n",
    "files_LACbusiness=[x for x in os.listdir(path+'FrontEnd_Input_'+analyst+'/') if 'LAC' in x and 'business' in x]\n",
    "LACbusiness=pd.read_csv(path+'FrontEnd_Input_'+analyst+'/'+files_LACbusiness[0])\n",
    "for f in files_LACbusiness[1:]:\n",
    "    Intermediate=pd.read_csv(path+'FrontEnd_Input_'+analyst+'/'+f)\n",
    "    LACbusiness=pd.concat([LACbusiness,Intermediate])\n",
    "LACbusiness['Route']=LACbusiness['Route'].astype('str')\n",
    "LACbusiness['DepDate']=LACbusiness['DepDate'].astype('str')    \n",
    "LACbusiness['FltNum']=LACbusiness['FltNum'].astype('str')\n",
    "LACbusiness['dtime']=LACbusiness['dtime'].astype('str')\n",
    "\n",
    "files_BookingPace=[x for x in os.listdir(path+'FrontEnd_Input_'+analyst+'/') if 'BookingPace' in x]\n",
    "BookingPace=pd.read_csv(path+'FrontEnd_Input_'+analyst+'/'+files_BookingPace[0])\n",
    "for f in files_BookingPace[1:]:\n",
    "    Intermediate=pd.read_csv(path+'FrontEnd_Input_'+analyst+'/'+f)\n",
    "    BookingPace=pd.concat([BookingPace,Intermediate])\n",
    "BookingPace['Route']=BookingPace['Route'].astype('str')\n",
    "BookingPace['DepDate']=BookingPace['DepDate'].astype('str')    \n",
    "BookingPace['FltNum']=BookingPace['FltNum'].astype('str')\n",
    "BookingPace['dtime']=BookingPace['dtime'].astype('str')\n",
    "\n",
    "files_BidPrice=[x for x in os.listdir(path+'FrontEnd_Input_'+analyst+'/') if 'BidPrice' in x]\n",
    "BidPrice=pd.read_csv(path+'FrontEnd_Input_'+analyst+'/'+files_BidPrice[0])\n",
    "for f in files_BidPrice[1:]:\n",
    "    Intermediate=pd.read_csv(path+'FrontEnd_Input_'+analyst+'/'+f)\n",
    "    BidPrice=pd.concat([BidPrice,Intermediate])\n",
    "BidPrice['Route']=BidPrice['Route'].astype('str')\n",
    "BidPrice['DepDate']=BidPrice['DepDate'].astype('str')    \n",
    "BidPrice['FltNum']=BidPrice['FltNum'].astype('str')\n",
    "BidPrice['dtime']=BidPrice['dtime'].astype('str')\n",
    "\n",
    "files_ClassBooking=[x for x in os.listdir(path+'FrontEnd_Input_'+analyst+'/') if 'ClassBooking' in x]\n",
    "ClassBooking=pd.read_csv(path+'FrontEnd_Input_'+analyst+'/'+files_ClassBooking[0])\n",
    "for f in files_ClassBooking[1:]:\n",
    "    Intermediate=pd.read_csv(path+'FrontEnd_Input_'+analyst+'/'+f)\n",
    "    ClassBooking=pd.concat([ClassBooking,Intermediate])\n",
    "\n",
    "ClassBooking['Route']=ClassBooking['Route'].astype('str')\n",
    "ClassBooking['DepDate']=ClassBooking['DepDate'].astype('str')    \n",
    "ClassBooking['FltNum']=ClassBooking['FltNum'].astype('str')\n",
    "ClassBooking['dtime']=ClassBooking['dtime'].astype('str')\n",
    "\n",
    "Surveillance=pd.read_csv(path+'FrontEnd_Input_'+analyst+'/Surveillance.csv')\n",
    "Surveillance['DepDate']=Surveillance['DepDate'].apply(lambda x: pd.to_datetime(x))\n",
    "Surveillance['FltNum']=Surveillance['FltNum'].astype('str')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import external stylesheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "external_stylesheets = ['https://codepen.io/chriddyp/pen/bWLwgP.css']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectors for dropdown menues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mapping_StrToDt=pd.concat([Series(Risk['DepDate'].unique()),Series([pd.to_datetime(x) for x in Risk['DepDate'].unique()])],axis=1)\n",
    "Mapping_StrToDt.columns=['DepDate','DepDate_new']\n",
    "Risk=Risk.merge(Mapping_StrToDt,on='DepDate')\n",
    "Risk['DepDate']=Risk['DepDate_new']\n",
    "Risk=Risk[[x for x in Risk.columns if x!='DepDate_new']]\n",
    "\n",
    "#################################################################\n",
    "\n",
    "Mapping_StrToDt=pd.concat([Series(IdealCurve['DepDate'].unique()),Series([pd.to_datetime(x) for x in IdealCurve['DepDate'].unique()])],axis=1)\n",
    "Mapping_StrToDt.columns=['DepDate','DepDate_new']\n",
    "IdealCurve=IdealCurve.merge(Mapping_StrToDt,on='DepDate')\n",
    "IdealCurve['DepDate']=IdealCurve['DepDate_new']\n",
    "IdealCurve=IdealCurve[[x for x in IdealCurve.columns if x!='DepDate_new']]\n",
    "\n",
    "#################################################################\n",
    "\n",
    "Mapping_StrToDt=pd.concat([Series(Actuals['DepDate'].unique()),Series([pd.to_datetime(x) for x in Actuals['DepDate'].unique()])],axis=1)\n",
    "Mapping_StrToDt.columns=['DepDate','DepDate_new']\n",
    "Actuals=Actuals.merge(Mapping_StrToDt,on='DepDate')\n",
    "Actuals['DepDate']=Actuals['DepDate_new']\n",
    "Actuals=Actuals[[x for x in Actuals.columns if x!='DepDate_new']]\n",
    "\n",
    "#################################################################\n",
    "\n",
    "Mapping_StrToDt=pd.concat([Series(Capacity['DepDate'].unique()),Series([pd.to_datetime(x) for x in Capacity['DepDate'].unique()])],axis=1)\n",
    "Mapping_StrToDt.columns=['DepDate','DepDate_new']\n",
    "Capacity=Capacity.merge(Mapping_StrToDt,on='DepDate')\n",
    "Capacity['DepDate']=Capacity['DepDate_new']\n",
    "Capacity=Capacity[[x for x in Capacity.columns if x!='DepDate_new']]\n",
    "\n",
    "#################################################################\n",
    "\n",
    "Mapping_StrToDt=pd.concat([Series(GroupPax['DepDate'].unique()),Series([pd.to_datetime(x) for x in GroupPax['DepDate'].unique()])],axis=1)\n",
    "Mapping_StrToDt.columns=['DepDate','DepDate_new']\n",
    "GroupPax=GroupPax.merge(Mapping_StrToDt,on='DepDate')\n",
    "GroupPax['DepDate']=GroupPax['DepDate_new']\n",
    "GroupPax=GroupPax[[x for x in GroupPax.columns if x!='DepDate_new']]\n",
    "\n",
    "#################################################################\n",
    "\n",
    "Mapping_StrToDt=pd.concat([Series(BookingPace['DepDate'].unique()),Series([pd.to_datetime(x) for x in BookingPace['DepDate'].unique()])],axis=1)\n",
    "Mapping_StrToDt.columns=['DepDate','DepDate_new']\n",
    "BookingPace=BookingPace.merge(Mapping_StrToDt,on='DepDate')\n",
    "BookingPace['DepDate']=BookingPace['DepDate_new']\n",
    "BookingPace=BookingPace[[x for x in BookingPace.columns if x!='DepDate_new']]\n",
    "\n",
    "#################################################################\n",
    "\n",
    "Mapping_StrToDt=pd.concat([Series(LACeco['DepDate'].unique()),Series([pd.to_datetime(x) for x in LACeco['DepDate'].unique()])],axis=1)\n",
    "Mapping_StrToDt.columns=['DepDate','DepDate_new']\n",
    "LACeco=LACeco.merge(Mapping_StrToDt,on='DepDate')\n",
    "LACeco['DepDate']=LACeco['DepDate_new']\n",
    "LACeco=LACeco[[x for x in LACeco.columns if x!='DepDate_new']]\n",
    "LACeco=LACeco.rename(columns={'LAC': 'LAC_eco'})\n",
    "LACeco=LACeco.drop_duplicates(subset=['Dprio','Route','DepDate','FltNum'])\n",
    "LACeco=LACeco[[x for x in LACeco.columns if x!='dtime']]\n",
    "\n",
    "#################################################################\n",
    "\n",
    "Mapping_StrToDt=pd.concat([Series(LACbusiness['DepDate'].unique()),Series([pd.to_datetime(x) for x in LACbusiness['DepDate'].unique()])],axis=1)\n",
    "Mapping_StrToDt.columns=['DepDate','DepDate_new']\n",
    "LACbusiness=LACbusiness.merge(Mapping_StrToDt,on='DepDate')\n",
    "LACbusiness['DepDate']=LACbusiness['DepDate_new']\n",
    "LACbusiness=LACbusiness[[x for x in LACbusiness.columns if x!='DepDate_new']]\n",
    "LACbusiness=LACbusiness.rename(columns={'LAC': 'LAC_bus'})\n",
    "LACbusiness=LACbusiness.drop_duplicates(subset=['Dprio','Route','DepDate','FltNum'])\n",
    "LACbusiness=LACbusiness[[x for x in LACbusiness.columns if x!='dtime']]\n",
    "\n",
    "#################################################################\n",
    "\n",
    "Mapping_StrToDt=pd.concat([Series(BidPrice['DepDate'].unique()),Series([pd.to_datetime(x) for x in BidPrice['DepDate'].unique()])],axis=1)\n",
    "Mapping_StrToDt.columns=['DepDate','DepDate_new']\n",
    "BidPrice=BidPrice.merge(Mapping_StrToDt,on='DepDate')\n",
    "BidPrice['DepDate']=BidPrice['DepDate_new']\n",
    "BidPrice=BidPrice[[x for x in BidPrice.columns if x!='DepDate_new']]\n",
    "\n",
    "\n",
    "BidPrice=BidPrice.drop_duplicates(subset=['Dprio','Route','Cabin','DepDate','FltNum'])\n",
    "BidPrice=BidPrice[[x for x in BidPrice.columns if x!='dtime']]\n",
    "\n",
    "#################################################################\n",
    "\n",
    "Mapping_StrToDt=pd.concat([Series(ClassBooking['DepDate'].unique()),Series([pd.to_datetime(x) for x in ClassBooking['DepDate'].unique()])],axis=1)\n",
    "Mapping_StrToDt.columns=['DepDate','DepDate_new']\n",
    "ClassBooking=ClassBooking.merge(Mapping_StrToDt,on='DepDate')\n",
    "ClassBooking['DepDate']=ClassBooking['DepDate_new']\n",
    "ClassBooking=ClassBooking[[x for x in ClassBooking.columns if x!='DepDate_new']]\n",
    "ClassBooking=ClassBooking.rename(columns={'LAC': 'LAC_bus'})\n",
    "ClassBooking=ClassBooking.drop_duplicates(subset=['Dprio','Route','DepDate','FltNum'])\n",
    "ClassBooking=ClassBooking[[x for x in ClassBooking.columns if x!='dtime']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "Risk=Risk.loc[(Risk['DepDate']>=pd.to_datetime(datetime.datetime.today().strftime('%Y-%m-%d')))&(Risk['DepDate']<=pd.to_datetime('2019-09-30')),:]\n",
    "IdealCurve=IdealCurve.loc[(IdealCurve['DepDate']>=pd.to_datetime(datetime.datetime.today().strftime('%Y-%m-%d')))&(IdealCurve['DepDate']<=pd.to_datetime('2019-09-30')),:]\n",
    "Actuals=Actuals.loc[(Actuals['DepDate']>=pd.to_datetime(datetime.datetime.today().strftime('%Y-%m-%d')))&(Actuals['DepDate']<=pd.to_datetime('2019-09-30')),:]\n",
    "GroupPax=GroupPax.loc[(GroupPax['DepDate']>=pd.to_datetime(datetime.datetime.today().strftime('%Y-%m-%d')))&(GroupPax['DepDate']<=pd.to_datetime('2019-09-30')),:]\n",
    "Capacity=Capacity.loc[(Capacity['DepDate']>=pd.to_datetime(datetime.datetime.today().strftime('%Y-%m-%d')))&(Capacity['DepDate']<=pd.to_datetime('2019-09-30')),:]\n",
    "BidPrice=BidPrice.loc[(BidPrice['DepDate']>=pd.to_datetime(datetime.datetime.today().strftime('%Y-%m-%d')))&(BidPrice['DepDate']<=pd.to_datetime('2019-09-30')),:]\n",
    "ClassBooking=ClassBooking.loc[(ClassBooking['DepDate']>=pd.to_datetime(datetime.datetime.today().strftime('%Y-%m-%d')))&(ClassBooking['DepDate']<=pd.to_datetime('2019-09-30')),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "LACeco['Dtt']=(LACeco['DepDate']-pd.to_datetime(datetime.datetime.today().strftime('%Y-%m-%d'))).apply(lambda x: np.float(x.days))\n",
    "LACbusiness['Dtt']=(LACbusiness['DepDate']-pd.to_datetime(datetime.datetime.today().strftime('%Y-%m-%d'))).apply(lambda x: np.float(x.days))\n",
    "BookingPace['Dtt']=(BookingPace['DepDate']-pd.to_datetime(datetime.datetime.today().strftime('%Y-%m-%d'))).apply(lambda x: np.float(x.days))\n",
    "BidPrice['Dtt']=(BidPrice['DepDate']-pd.to_datetime(datetime.datetime.today().strftime('%Y-%m-%d'))).apply(lambda x: np.float(x.days))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "BidPrice=BidPrice.loc[BidPrice['Cabin']=='Eco.',['Route','FltNum','DepDate','Dprio','Dtt','Bid Price']]\\\n",
    ".merge(BidPrice.loc[BidPrice['Cabin']=='Bus.',['Route','FltNum','DepDate','Dprio','Dtt','Bid Price']],\n",
    "       on=['Route','FltNum','DepDate','Dprio','Dtt'],how='outer')\n",
    "\n",
    "BidPrice=BidPrice.rename(columns={'Bid Price_x': 'BidPrice_eco', 'Bid Price_y': 'BidPrice_bus'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "Risk=Risk.merge(LACeco.loc[LACeco['Dprio']==LACeco['Dtt'],['Route','DepDate','FltNum','Direction','LAC_eco']].drop_duplicates(),\n",
    "                on=['Route','DepDate','FltNum'],how='left')\n",
    "\n",
    "Risk=Risk.merge(LACbusiness.loc[LACbusiness['Dprio']==LACbusiness['Dtt'],['Route','DepDate','FltNum','Direction','LAC_bus']].drop_duplicates(),\n",
    "                on=['Route','DepDate','FltNum'],how='left')\n",
    "\n",
    "Risk=Risk.merge(BookingPace.loc[BookingPace['Dprio']==BookingPace['Dtt'],['Route','DepDate','FltNum',\n",
    "            'Underpace_7','Underpace_3','Overpace_7','Overpace_3']].drop_duplicates(),\n",
    "                on=['Route','DepDate','FltNum'],how='left')\n",
    "\n",
    "Risk=Risk.merge(BidPrice.loc[BidPrice['Dprio']==BidPrice['Dtt'],['Route','DepDate','FltNum','BidPrice_eco','BidPrice_bus']].drop_duplicates(),\n",
    "                on=['Route','DepDate','FltNum'],how='left')\n",
    "\n",
    "\n",
    "Risk=Risk[['Route','DepDate','FltNum','month','dday',\n",
    "     'SpillageRisk','SpoilageRisk','Overpace_7','Overpace_3','Underpace_7','Underpace_3','LAC_eco','LAC_bus','BidPrice_eco',\n",
    "          'BidPrice_bus']]\n",
    "Risk['Surv.']=''\n",
    "Risk['Since']=''\n",
    "#Risk['Comment']=''\n",
    "\n",
    "Risk=Risk.merge(Surveillance,on=['Route','DepDate','FltNum'],how='left')\n",
    "Risk['Surv._x']=Risk['Surv._y']\n",
    "Risk['Since_x']=Risk['Since_y']\n",
    "Risk=Risk[[x for x in Risk.columns if '_y' not in x]]\n",
    "Risk.columns=[x.replace('_x','') for x in Risk.columns]\n",
    "Risk['Surv.']=Risk['Surv.'].fillna('')\n",
    "Risk['Since']=Risk['Since'].fillna('')\n",
    "\n",
    "# Risk=Risk.merge(Comments,on=['Route','DepDate','FltNum'],how='left')\n",
    "# Risk['Comment_x']=Risk['Comment_y']\n",
    "# Risk=Risk[[x for x in Risk.columns if '_y' not in x]]\n",
    "# Risk.columns=[x.replace('_x','') for x in Risk.columns]\n",
    "# Risk['Comment']=Risk['Comment'].fillna('')\n",
    "\n",
    "# Risk=Risk.sort_values(by=['Route','DepDate','FltNum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "Risk['SpoilageRisk']=Risk['SpoilageRisk'].apply(lambda x: np.round(x,2))\n",
    "Risk['SpillageRisk']=Risk['SpillageRisk'].apply(lambda x: np.round(x,2))\n",
    "Risk['Underpace_7']=Risk['Underpace_7'].apply(lambda x: np.round(x,2))\n",
    "Risk['Underpace_3']=Risk['Underpace_3'].apply(lambda x: np.round(x,2))\n",
    "Risk['Overpace_7']=Risk['Overpace_7'].apply(lambda x: np.round(x,2))\n",
    "Risk['Overpace_3']=Risk['Overpace_3'].apply(lambda x: np.round(x,2))\n",
    "Risk['BidPrice_eco']=Risk['BidPrice_eco'].apply(lambda x: np.round(x,2))\n",
    "Risk['BidPrice_bus']=Risk['BidPrice_bus'].apply(lambda x: np.round(x,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate=Risk[['Route','DepDate','FltNum']].drop_duplicates()\n",
    "checkbox_values=intermediate\\\n",
    ".sort_values(by=['Route','DepDate','FltNum']).transpose().values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "LACeco=LACeco.sort_values(by=['Route', 'DepDate', 'FltNum', 'Dprio'],ascending=[True,True,True,False])\n",
    "Capacity=Capacity.sort_values(by=['Route', 'DepDate', 'FltNum', 'Dprio'],ascending=[True,True,True,False])\n",
    "BidPrice=BidPrice.sort_values(by=['Route', 'DepDate', 'FltNum', 'Dprio'],ascending=[True,True,True,False])\n",
    "\n",
    "class_vector=['W','R','A','N','G','O','H','V','F','X','L','U','P','S','B','Q','K','M','Y']\n",
    "class_map=pd.concat([Series(class_vector),\n",
    "                    Series(range(1,len(class_vector)+1))],axis=1)\n",
    "class_map.columns=['LAC','Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "Month_mapping=DataFrame([['January','February','March','April','May','June','July','August','September',\n",
    "                         'October','November','December'],[x for x in range(1,13)]],index=['month','month_new']).transpose()\n",
    "Risk=Risk.merge(Month_mapping,on='month')\n",
    "Risk['month']=Risk['month_new']\n",
    "Risk=Risk[[x for x in Risk.columns if x!='month_new']]\n",
    "\n",
    "Day_mapping=DataFrame([['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday'],\n",
    "                       [x for x in range(1,8)]],index=['dday','dday_new']).transpose()\n",
    "Risk=Risk.merge(Day_mapping,on='dday')\n",
    "Risk['dday']=Risk['dday_new']\n",
    "Risk=Risk[[x for x in Risk.columns if x!='dday_new']]\n",
    "\n",
    "Risk=Risk.sort_values(by=['Route','DepDate', 'FltNum']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps=5\n",
    "r1, g1, b1 = 144,238,144\n",
    "r2, g2, b2 = 0,100,0\n",
    "rdelta, gdelta, bdelta = (r2-r1)/steps, (g2-g1)/steps, (b2-b1)/steps\n",
    "output_green=[]\n",
    "for step in range(steps):\n",
    "    r1 += rdelta\n",
    "    g1 += gdelta\n",
    "    b1 += bdelta\n",
    "    output_green.append((int(round(r1)), int(round(g1)), int(round(b1))))\n",
    "    \n",
    "steps=9\n",
    "r1, g1, b1 = 255,165,0\n",
    "r2, g2, b2 = 255,69,0\n",
    "rdelta, gdelta, bdelta = (r2-r1)/steps, (g2-g1)/steps, (b2-b1)/steps\n",
    "output_orange=[]\n",
    "for step in range(steps):\n",
    "    r1 += rdelta\n",
    "    g1 += gdelta\n",
    "    b1 += bdelta\n",
    "    output_orange.append((int(round(r1)), int(round(g1)), int(round(b1))))\n",
    "\n",
    "steps=4\n",
    "r1, g1, b1 = 255,0,0\n",
    "r2, g2, b2 = 139,0,0\n",
    "rdelta, gdelta, bdelta = (r2-r1)/steps, (g2-g1)/steps, (b2-b1)/steps\n",
    "output_red=[]\n",
    "for step in range(steps):\n",
    "    r1 += rdelta\n",
    "    g1 += gdelta\n",
    "    b1 += bdelta\n",
    "    output_red.append((int(round(r1)), int(round(g1)), int(round(b1))))\n",
    "    \n",
    "steps=3\n",
    "r1, g1, b1 = 128,0,128\n",
    "r2, g2, b2 = 75,0,130\n",
    "rdelta, gdelta, bdelta = (r2-r1)/steps, (g2-g1)/steps, (b2-b1)/steps\n",
    "output_purple=[]\n",
    "for step in range(steps):\n",
    "    r1 += rdelta\n",
    "    g1 += gdelta\n",
    "    b1 += bdelta\n",
    "    output_purple.append((int(round(r1)), int(round(g1)), int(round(b1))))\n",
    "    \n",
    "class_vector_all=['T','I','W','R','A','N','G','O','H','V','F','X','L','U','P','S','B','Q','K','M','Y','D','Z','C','J']\n",
    "class_color=dict(zip(class_vector_all,\n",
    "['grey','grey','blue']+['rgb'+str(x)+'' for x in output_green]\\\n",
    "+['rgb'+str(x)+'' for x in output_orange]\\\n",
    "+['rgb'+str(x)+'' for x in output_red]+['grey']\\\n",
    "+['rgb'+str(x)+'' for x in output_purple]))\n",
    "class_vector_all.reverse()\n",
    "class_data=[x for x in ClassBooking.columns if len(x)==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "line_columns_Pax = ['Actual Bookings']\n",
    "linecolor_dict_Pax = dict(zip(line_columns_Pax,['black']))\n",
    "linedash_dict_Pax = dict(zip(line_columns_Pax,['solid']))\n",
    "name_dict_Pax = dict(zip(line_columns_Pax,['Actual Bookings']))\n",
    "\n",
    "line_columns_Ideal = ['Ramp-up frontier', 'Ideal curve (80% LF)', 'Ideal curve (100% LF)', \n",
    "                    'Phase-down frontier']\n",
    "linecolor_dict_Ideal = dict(zip(line_columns_Ideal,['red', 'blue', 'green', '#E0115F']))\n",
    "linedash_dict_Ideal = dict(zip(line_columns_Ideal,['dot', 'solid', 'solid', 'dot']))\n",
    "name_dict_Ideal = dict(zip(line_columns_Ideal,['Ramp-up frontier', 'Ideal curve (80% LF)', \n",
    "                        'Ideal curve (100% LF)', 'Phase-down frontier']))\n",
    "\n",
    "line_columns_Capacity = ['Real Cabin Capacity']\n",
    "linecolor_dict_Capacity = dict(zip(line_columns_Capacity,['#3c2411']))\n",
    "linedash_dict_Capacity = dict(zip(line_columns_Capacity,['solid']))\n",
    "name_dict_Capacity = dict(zip(line_columns_Capacity,['Cabin Capacity']))\n",
    "\n",
    "rename_dict=dict(zip(Risk.columns,\n",
    "['Route', 'Departure Date', 'Flight Number', 'Month', 'Weekday', \n",
    " 'Spillage', 'Spoilage',  'Over (7d)', 'Over (3d)', 'Under (7d)', 'Under (3d)', \n",
    " 'eco.', 'bus.', 'eco.', 'bus.', 'Surv.', 'Since']))\n",
    "\n",
    "line_columns_Lac = [x for x in class_vector_all if x in class_data]\n",
    "linecolor_dict_Lac = dict(zip(line_columns_Lac,\n",
    "[class_color[x] for x in line_columns_Lac]))\n",
    "linedash_dict_Lac = dict(zip(line_columns_Lac,['solid']))\n",
    "name_dict_Lac = dict(zip(line_columns_Lac,['LAC (eco.)']))\n",
    "\n",
    "line_columns_Bid = ['BidPrice_eco']\n",
    "linecolor_dict_Bid = dict(zip(line_columns_Bid,['black']))\n",
    "linedash_dict_Bid = dict(zip(line_columns_Bid,['solid']))\n",
    "name_dict_Bid = dict(zip(line_columns_Bid,['Bid (eco.)']))\n",
    "\n",
    "line_columns_ClassBooking = [x for x in class_vector_all if x in class_data]\n",
    "# linecolor_dict_ClassBooking = dict(zip(line_columns_ClassBooking,\n",
    "# ['rgb'+str(x)+'' for x in sns.color_palette(\"Blues\", len(line_columns_ClassBooking))]))\n",
    "linecolor_dict_ClassBooking = dict(zip(line_columns_ClassBooking,\n",
    "[class_color[x] for x in line_columns_ClassBooking]))\n",
    "linedash_dict_ClassBooking = dict(zip(line_columns_ClassBooking,['solid']*len(line_columns_ClassBooking)))\n",
    "name_dict_ClassBooking = dict(zip(line_columns_ClassBooking,line_columns_ClassBooking))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = datetime.datetime.utcfromtimestamp(0)\n",
    "def unix_time_millis(dt):\n",
    "    return int((dt - epoch).total_seconds())#* 1000.0\n",
    "\n",
    "def get_marks_from_start_end(start, end):\n",
    "    ''' Returns dict with one item per month\n",
    "    {1440080188.1900003: '2015-08',\n",
    "    '''\n",
    "    result = []\n",
    "    current = start\n",
    "    while current <= end:\n",
    "        result.append(current)\n",
    "        current += relativedelta(weeks=1)\n",
    "    return {unix_time_millis(m):(str(m.strftime('%m-%d'))) for m in result}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Color schemes for DataTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_headers={'Route': 'Flight Properties', 'DepDate': 'Flight Properties', 'FltNum': 'Flight Properties',\n",
    "              'month': 'Flight Properties', 'dday': 'Flight Properties', 'SpillageRisk': 'Locational Risk',\n",
    "              'SpoilageRisk': 'Locational Risk', 'Overpace_7': 'Pacing Risk', 'Overpace_3': 'Pacing Risk',\n",
    "              'Underpace_7': 'Pacing Risk', 'Underpace_3': 'Pacing Risk', 'LAC_eco': 'LAC', 'LAC_bus': 'LAC',\n",
    "              'BidPrice_eco': 'Bid Price', 'BidPrice_bus': 'Bid Price', 'Surv.': 'Steering', 'Since': 'Steering'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colors_warning={'loc_ok': 'green','loc_06': '#CCCC33', 'loc_07': '#CC6600', 'loc_08': '#CC0000',\n",
    "#                'pace_ok': '#32CD32', 'pace_06': '#F0E68C', 'pace_07': '#FF7F50', 'pace_08': '#B22222'}\n",
    "colors_warning={'loc_ok': 'green','loc_06': 'green', 'loc_07': 'green', 'loc_08': '#CC0000',\n",
    "               'pace_ok': '#32CD32', 'pace_06': '#32CD32', 'pace_07': '#32CD32', 'pace_08': '#B22222'}\n",
    "colors_columns={'location': '#989898', 'pacing': '#C8C8C8', 'lac': '#ADD8E6', 'bid': '#DDA0DD', 'steer': '#FFFAFA'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAGE_SIZE = 20\n",
    "\n",
    "app = dash.Dash(__name__, external_stylesheets=external_stylesheets)\n",
    "\n",
    "app.layout = html.Div(children=[\n",
    "        html.Div([html.Div(style={'width': '10%', 'display': 'inline-block'}),\n",
    "        html.Img(src=app.get_asset_url('LuxairGroup.jpg'), \n",
    "              style = {'backgroundColor' : '#66b3cc','display': 'inline-block', 'vertical-align': 'middle', \n",
    "                       'width': '10%', 'height': '7em'}),\n",
    "        html.H4(children='Booking Curve Steering System',style={\n",
    "            'textAlign': 'center',\n",
    "            'color': 'black','height': '1em', 'display': 'inline-block', 'width': '64%'}),\n",
    "            html.Img(src=app.get_asset_url('Luxair.jpg'), \n",
    "              style = {'backgroundColor' : '#66b3cc','display': 'inline-block', 'vertical-align': 'middle',\n",
    "                       'width': '10%', 'height': '7em'}),\n",
    "        html.Div(style={'width': '10%', 'display': 'inline-block', 'vertical-align': 'middle'})\n",
    "                 ],\n",
    "        style={'margin-bottom': '-4em'})\n",
    "     ,\n",
    "    # ROUTE DROPDOWN AND DATE SLIDER\n",
    "    \n",
    "        # DROPDOWN\n",
    "html.Div([html.Div(style={'width': '25%', 'margin-bottom': '1em', 'display': 'inline-block'}),\n",
    "    html.Div([html.Div([html.Label('Route', style={'textAlign': 'center', 'font-weight': 'bold'}), \n",
    "    dcc.Dropdown(id = 'dropdown_routes',\n",
    "    options=[],\n",
    "    placeholder=\"Select a route\",                                 \n",
    "    value=sorted(set(checkbox_values[0])),\n",
    "    multi=True)],\n",
    "    style={'margin-bottom': '0.5em', 'width': '80%', 'margin-left': '6em'})\n",
    "    ,\n",
    "    html.Div([html.Label('Flight Number', style={'textAlign': 'center', 'font-weight': 'bold'}), \n",
    "    dcc.Checklist(id = 'checklist_table_fltnum',\n",
    "    options=[],\n",
    "    values=sorted(set(checkbox_values[2])),\n",
    "    labelStyle = {'display': 'inline', 'cursor': 'pointer', 'margin-left': '0em'})       \n",
    "             ],   \n",
    "    style={'margin-bottom': '1em', 'textAlign': 'center'})\n",
    "    ,\n",
    "    html.Div([html.Label('Departure Date', style={'textAlign': 'center', 'margin-bottom': '0em', 'font-weight': 'bold'}),\n",
    "    dcc.RangeSlider(\n",
    "           id = 'datetime_RangeSlider',\n",
    "           updatemode = 'mouseup', #don't let it update till mouse released\n",
    "           min = unix_time_millis(min(checkbox_values[1])),\n",
    "           max = unix_time_millis(max(checkbox_values[1])),\n",
    "           value = [unix_time_millis(min(checkbox_values[1])),\n",
    "                   unix_time_millis(max(checkbox_values[1]))],\n",
    "           #TODO add markers for key dates\n",
    "           marks=get_marks_from_start_end(min(checkbox_values[1]),max(checkbox_values[1])),\n",
    "       )],\n",
    "    style={'margin-bottom': '2em', 'width': '80%', 'margin-left': '6em'})\n",
    "             ], \n",
    "    style={'width': '50%', 'margin-bottom': '1em', 'margin-top': '0','display': 'inline-block', 'background-color': 'lightgrey'})\n",
    "    ,\n",
    "    html.Div(style={'width': '25%', 'margin-bottom': '0.5em', 'margin-top': '-3em', 'display': 'inline-block'})\n",
    "    ])\n",
    "    ,\n",
    "    # CONTAINERS\n",
    "    \n",
    "        # TABLE CONTAINER\n",
    "    html.Div([dash_table.DataTable(\n",
    "            id = 'booking_table',\n",
    "            #columns=[{'id': c, 'name': [group_headers[c],rename_dict[c]], 'editable': 'True'} if c=='Comment' \\\n",
    "            #         else {'id': c, 'name': [group_headers[c],rename_dict[c]], 'editable': 'False'} for c in Risk.columns],\n",
    "            columns=[{'id': c, 'name': [group_headers[c],rename_dict[c]]} for c in Risk.columns],          \n",
    "            style_header={'backgroundColor': 'rgb(30, 30, 30)','color': 'white', 'textAlign': 'center'},\n",
    "\n",
    "             style_cell_conditional=[              \n",
    "                 \n",
    "             {\n",
    "                 'if': {'column-id': 'Route'},\n",
    "                 'color': 'white',\n",
    "                 'backgroundColor': 'rgb(50, 50, 50)',\n",
    "                 'textAlign': 'center'\n",
    "             },\n",
    "             ############################################    \n",
    "                 {\n",
    "                 'if': {\n",
    "                     'column_id': 'SpoilageRisk'\n",
    "                 },\n",
    "                 'backgroundColor': colors_warning['loc_ok'],\n",
    "                 'color': 'black',\n",
    "                 'textAlign': 'center'\n",
    "            },{\n",
    "                 'if': {\n",
    "                     'column_id': 'SpoilageRisk',\n",
    "                     'filter': '{SpoilageRisk} >= 0.6',\n",
    "                 },\n",
    "                 'backgroundColor': colors_warning['loc_06'],\n",
    "                 'color': 'black',\n",
    "                 'textAlign': 'center'\n",
    "            },{\n",
    "                 'if': {\n",
    "                     'column_id': 'SpoilageRisk',\n",
    "                     'filter': '{SpoilageRisk} >= 0.7',\n",
    "                 },\n",
    "                 'backgroundColor': colors_warning['loc_07'],\n",
    "                 'color': 'black',\n",
    "                 'textAlign': 'center'\n",
    "            },\n",
    "                 {\n",
    "                 'if': {\n",
    "                     'column_id': 'SpoilageRisk',\n",
    "                     'filter': '{SpoilageRisk} >= 0.8',\n",
    "                 },\n",
    "                 'backgroundColor': colors_warning['loc_08'],\n",
    "                 'color': 'black',\n",
    "                 'textAlign': 'center'\n",
    "            },\n",
    "            ############################################       \n",
    "                 {\n",
    "                 'if': {\n",
    "                     'column_id': 'SpillageRisk'\n",
    "                 },\n",
    "                 'backgroundColor': 'green',\n",
    "                 'color': 'black',\n",
    "                 'textAlign': 'center'\n",
    "            },{\n",
    "                 'if': {\n",
    "                     'column_id': 'SpillageRisk',\n",
    "                     'filter': '{SpillageRisk} >= 0.6',\n",
    "                 },\n",
    "                 'backgroundColor': colors_warning['loc_06'],\n",
    "                 'color': 'black',\n",
    "                 'textAlign': 'center'\n",
    "            },\n",
    "                 {\n",
    "                 'if': {\n",
    "                     'column_id': 'SpillageRisk',\n",
    "                     'filter': '{SpillageRisk} >= 0.7',\n",
    "                 },\n",
    "                 'backgroundColor': colors_warning['loc_07'],\n",
    "                 'color': 'black',\n",
    "                 'textAlign': 'center'\n",
    "            },\n",
    "                 {\n",
    "                 'if': {\n",
    "                     'column_id': 'SpillageRisk',\n",
    "                     'filter': '{SpillageRisk} >= 0.8',\n",
    "                 },\n",
    "                 'backgroundColor': colors_warning['loc_08'],\n",
    "                 'color': 'black',\n",
    "                 'textAlign': 'center'\n",
    "            },\n",
    "            ############################################\n",
    "                 {\n",
    "                 'if': {\n",
    "                     'column_id': 'Overpace_7'\n",
    "                 },\n",
    "                 'backgroundColor': colors_warning['pace_ok'],\n",
    "                 'color': 'black',\n",
    "                 'textAlign': 'center'\n",
    "            },{\n",
    "                 'if': {\n",
    "                     'column_id': 'Overpace_7',\n",
    "                     'filter': '{Overpace_7} >= 0.6',\n",
    "                 },\n",
    "                 'backgroundColor': colors_warning['pace_06'],\n",
    "                 'color': 'black',\n",
    "                 'textAlign': 'center'\n",
    "            },\n",
    "                 {\n",
    "                 'if': {\n",
    "                     'column_id': 'Overpace_7',\n",
    "                     'filter': '{Overpace_7} >= 0.7',\n",
    "                 },\n",
    "                 'backgroundColor': colors_warning['pace_07'],\n",
    "                 'color': 'black',\n",
    "                 'textAlign': 'center'\n",
    "            },\n",
    "                 {\n",
    "                 'if': {\n",
    "                     'column_id': 'Overpace_7',\n",
    "                     'filter': '{Overpace_7} >= 0.8',\n",
    "                 },\n",
    "                 'backgroundColor': colors_warning['pace_08'],\n",
    "                 'color': 'black',\n",
    "                 'textAlign': 'center'\n",
    "            },                 \n",
    "            ############################################\n",
    "                 {\n",
    "                 'if': {\n",
    "                     'column_id': 'Overpace_3'\n",
    "                 },\n",
    "                 'backgroundColor': colors_warning['pace_ok'],\n",
    "                 'color': 'black',\n",
    "                 'textAlign': 'center'\n",
    "            },{\n",
    "                 'if': {\n",
    "                     'column_id': 'Overpace_3',\n",
    "                     'filter': '{Overpace_3} >= 0.6',\n",
    "                 },\n",
    "                 'backgroundColor': colors_warning['pace_06'],\n",
    "                 'color': 'black',\n",
    "                 'textAlign': 'center'\n",
    "            },\n",
    "                 {\n",
    "                 'if': {\n",
    "                     'column_id': 'Overpace_3',\n",
    "                     'filter': '{Overpace_3} >= 0.7',\n",
    "                 },\n",
    "                 'backgroundColor': colors_warning['pace_07'],\n",
    "                 'color': 'black',\n",
    "                 'textAlign': 'center'\n",
    "            },\n",
    "                 {\n",
    "                 'if': {\n",
    "                     'column_id': 'Overpace_3',\n",
    "                     'filter': '{Overpace_3} >= 0.8',\n",
    "                 },\n",
    "                 'backgroundColor': colors_warning['pace_08'],\n",
    "                 'color': 'black',\n",
    "                 'textAlign': 'center'\n",
    "            },\n",
    "            ############################################\n",
    "                 {\n",
    "                 'if': {\n",
    "                     'column_id': 'Underpace_7'\n",
    "                 },\n",
    "                 'backgroundColor': colors_warning['pace_ok'],\n",
    "                 'color': 'black',\n",
    "                 'textAlign': 'center'\n",
    "            },{\n",
    "                 'if': {\n",
    "                     'column_id': 'Underpace_7',\n",
    "                     'filter': '{Underpace_7} >= 0.6',\n",
    "                 },\n",
    "                 'backgroundColor': colors_warning['pace_06'],\n",
    "                 'color': 'black',\n",
    "                 'textAlign': 'center'\n",
    "            },\n",
    "                 {\n",
    "                 'if': {\n",
    "                     'column_id': 'Underpace_7',\n",
    "                     'filter': '{Underpace_7} >= 0.7',\n",
    "                 },\n",
    "                 'backgroundColor': colors_warning['pace_07'],\n",
    "                 'color': 'black',\n",
    "                 'textAlign': 'center'\n",
    "            },\n",
    "                 {\n",
    "                 'if': {\n",
    "                     'column_id': 'Underpace_7',\n",
    "                     'filter': '{Underpace_7} >= 0.8',\n",
    "                 },\n",
    "                 'backgroundColor': colors_warning['pace_08'],\n",
    "                 'color': 'black',\n",
    "                 'textAlign': 'center'\n",
    "            },\n",
    "            ############################################\n",
    "                 {\n",
    "                 'if': {\n",
    "                     'column_id': 'Underpace_3'\n",
    "                 },\n",
    "                 'backgroundColor': colors_warning['pace_ok'],\n",
    "                 'color': 'black',\n",
    "                 'textAlign': 'center'\n",
    "            },{\n",
    "                 'if': {\n",
    "                     'column_id': 'Underpace_3',\n",
    "                     'filter': '{Underpace_3} >= 0.6',\n",
    "                 },\n",
    "                 'backgroundColor': colors_warning['pace_06'],\n",
    "                 'color': 'black',\n",
    "                 'textAlign': 'center'\n",
    "            },\n",
    "                 {\n",
    "                 'if': {\n",
    "                     'column_id': 'Underpace_3',\n",
    "                     'filter': '{Underpace_3} >= 0.7',\n",
    "                 },\n",
    "                 'backgroundColor': colors_warning['pace_07'],\n",
    "                 'color': 'black',\n",
    "                 'textAlign': 'center'\n",
    "            },\n",
    "                 {\n",
    "                 'if': {\n",
    "                     'column_id': 'Underpace_3',\n",
    "                     'filter': '{Underpace_3} >= 0.8',\n",
    "                 },\n",
    "                 'backgroundColor': colors_warning['pace_08'],\n",
    "                 'color': 'black',\n",
    "                 'textAlign': 'center'\n",
    "            },\n",
    "            ############################################\n",
    "            {\n",
    "                 'if': {\n",
    "                     'column_id': 'LAC_eco'\n",
    "                 },\n",
    "                 'backgroundColor': colors_columns['lac'],\n",
    "                 'color': 'black',\n",
    "                 'textAlign': 'center'\n",
    "            },\n",
    "            {\n",
    "                 'if': {\n",
    "                     'column_id': 'LAC_bus'\n",
    "                 },\n",
    "                 'backgroundColor': colors_columns['lac'],\n",
    "                 'color': 'black',\n",
    "                 'textAlign': 'center'\n",
    "            },\n",
    "            {\n",
    "                 'if': {\n",
    "                     'column_id': 'BidPrice_eco'\n",
    "                 },\n",
    "                 'backgroundColor': colors_columns['bid'],\n",
    "                 'color': 'black',\n",
    "                 'textAlign': 'center'\n",
    "            },\n",
    "            {\n",
    "                 'if': {\n",
    "                     'column_id': 'BidPrice_bus'\n",
    "                 },\n",
    "                 'backgroundColor': colors_columns['bid'],\n",
    "                 'color': 'black',\n",
    "                 'textAlign': 'center'\n",
    "            },\n",
    "            ############################################\n",
    "            {\n",
    "                 'if': {\n",
    "                     'column_id': 'Surv.'\n",
    "                 },\n",
    "                 'backgroundColor': colors_columns['steer'],\n",
    "                 'color': 'black',\n",
    "                 'textAlign': 'center'\n",
    "            },\n",
    "            {\n",
    "                 'if': {\n",
    "                     'column_id': 'Since'\n",
    "                 },\n",
    "                 'backgroundColor': colors_columns['steer'],\n",
    "                 'color': 'black',\n",
    "                 'textAlign': 'center'\n",
    "            }\n",
    "#             ,\n",
    "#             {\n",
    "#                  'if': {\n",
    "#                      'column_id': 'Comment'\n",
    "#                  },\n",
    "#                  'backgroundColor': colors_columns['steer'],\n",
    "#                  'color': 'black',\n",
    "#                  'textAlign': 'center'\n",
    "#             }\n",
    "             ],\n",
    "        \n",
    "        \n",
    "    merge_duplicate_headers=True,\n",
    "    n_fixed_rows=2,\n",
    "            style_cell={\n",
    "            # all three widths are needed\n",
    "            'minWidth': '50px', 'width': '50px', 'maxWidth': '50px',\n",
    "            'whiteSpace': 'normal'\n",
    "        },\n",
    "    style_table={\n",
    "        'maxHeight': '600px'\n",
    "    },\n",
    "\n",
    "    pagination_settings={\n",
    "        'current_page': 0,\n",
    "        'page_size': PAGE_SIZE\n",
    "    },        \n",
    "        \n",
    "    pagination_mode='be',        \n",
    "        \n",
    "    #filtering='be',\n",
    "    #filtering_settings='',\n",
    "\n",
    "    sorting='be',\n",
    "    sorting_type='multi',\n",
    "    sort_by=[]\n",
    "\n",
    "            ),\n",
    "    dcc.Interval(\n",
    "    id='interval-component',\n",
    "    interval=1*1250, # in milliseconds\n",
    "    n_intervals=0\n",
    "        )\n",
    "                       ],\n",
    "        \n",
    "        style={'width': '55%', 'margin-top': '0.5em', 'display': 'inline-block'})\n",
    "             \n",
    "             ,\n",
    "\n",
    "        # GRAPH CONTAINER                   \n",
    "#      html.Div(children=[dcc.Graph(id='graph')],\n",
    "#      style={'width': '47.5%', 'float': 'right', 'display': 'inline-block'},\n",
    "#              id='graph-container_pax') \n",
    "    \n",
    "        # GRAPH CONTAINER                   \n",
    "    html.Div([dcc.Tabs(id=\"tabs\", children=[\n",
    "        dcc.Tab(label='Booking Curve', children=[\n",
    "            html.Div([\n",
    "                dcc.Graph(\n",
    "                    id='graph-bc')\n",
    "                ])\n",
    "            ]),\n",
    "        dcc.Tab(label='Bookings by Class', children=[\n",
    "            html.Div([\n",
    "                dcc.Graph(\n",
    "                    id='graph-classbook')\n",
    "                ])\n",
    "            ]),\n",
    "        dcc.Tab(label='LAC', children=[\n",
    "            html.Div([\n",
    "                dcc.Graph(\n",
    "                    id='graph-lac')\n",
    "                ])\n",
    "            ]),\n",
    "        dcc.Tab(label='Bid Price', children=[\n",
    "            html.Div([\n",
    "                dcc.Graph(\n",
    "                    id='graph-bid')\n",
    "                ])\n",
    "            ])       \n",
    "    ])\n",
    "    ],style={'width': '45%', 'float': 'right', 'display': 'inline-block', 'margin-top': '0.5em'}),    \n",
    "    \n",
    "    \n",
    "    #html.Div(style={'width': '25%', 'margin-bottom': '2em', 'display': 'inline-block'}),\n",
    "              \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.callback(\n",
    "    Output(\"dropdown_routes\", \"options\"),\n",
    "    [Input(\"datetime_RangeSlider\", \"value\"),\n",
    "    Input(\"checklist_table_fltnum\", \"values\")]\n",
    "    )\n",
    "def set_checklist_route(values_depdate,values_fltnum):\n",
    "    subset=set([checkbox_values[0][i] for i in range(len(checkbox_values[0]))\\\n",
    "    if unix_time_millis(checkbox_values[1][i])>=int(values_depdate[0]) and unix_time_millis(checkbox_values[1][i])<=int(values_depdate[1])\\\n",
    "    if checkbox_values[2][i] in values_fltnum])\n",
    "    values=[{'label': i,'value': i} for i in sorted(subset)]\n",
    "    return values\n",
    "\n",
    "##########################################################\n",
    "\n",
    "@app.callback(\n",
    "    [Output(\"datetime_RangeSlider\", \"min\"),\n",
    "    Output(\"datetime_RangeSlider\", \"max\"),\n",
    "    Output(\"datetime_RangeSlider\", \"marks\")],\n",
    "    [Input(\"dropdown_routes\", \"value\"),\n",
    "    Input(\"checklist_table_fltnum\", \"values\")]\n",
    "    )\n",
    "def set_checklist_depdate(values_route,values_fltnum):\n",
    "    subset=set([checkbox_values[1][i] for i in range(len(checkbox_values[0]))\\\n",
    "    if checkbox_values[0][i] in values_route\\\n",
    "    and checkbox_values[2][i] in values_fltnum])\n",
    "    minimum=min([unix_time_millis(x) for x in subset])\n",
    "    maximum=max([unix_time_millis(x) for x in subset])\n",
    "    value=[minimum,maximum]\n",
    "    marks=get_marks_from_start_end([x for x in subset if unix_time_millis(x)==minimum][0],\n",
    "                                   [x for x in subset if unix_time_millis(x)==maximum][0])\n",
    "    return minimum, maximum, marks\n",
    "\n",
    "##########################################################\n",
    "\n",
    "@app.callback(\n",
    "    Output(\"checklist_table_fltnum\", \"options\"),\n",
    "    [Input(\"dropdown_routes\", \"value\"),\n",
    "    Input(\"datetime_RangeSlider\", \"value\")]\n",
    "    )\n",
    "def set_checklist_fltnum(values_route,values_depdate):\n",
    "    subset=set([checkbox_values[2][i] for i in range(len(checkbox_values[0]))\\\n",
    "    if checkbox_values[0][i] in values_route\\\n",
    "    and unix_time_millis(checkbox_values[1][i])>=int(values_depdate[0]) and unix_time_millis(checkbox_values[1][i])<=int(values_depdate[1])])\n",
    "    values=[{'label': i,'value': i} for i in sorted(subset)]\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.callback(Output('booking_table', 'data'),\n",
    "     #,\n",
    "    # Output('graph', 'figure')\n",
    "    [Input('dropdown_routes', 'value'),\n",
    "     Input('datetime_RangeSlider', 'value'),\n",
    "     Input('checklist_table_fltnum', 'values'),\n",
    "     Input('booking_table', 'pagination_settings'),\n",
    "     Input('booking_table', 'sort_by'),\n",
    "     Input('interval-component', 'n_intervals')\n",
    "     #,\n",
    "     #Input('booking_table', \"derived_virtual_selected_rows\")\n",
    "    ]\n",
    "    )\n",
    "def update_table(values_route, values_depdate, values_fltnum, \n",
    "    pagination_settings, sorting_settings,n):\n",
    "    #, derived_virtual_selected_rows):\n",
    "\n",
    "#     if derived_virtual_selected_rows is None:\n",
    "#         derived_virtual_selected_rows = []    \n",
    "    \n",
    "    #filtering_expressions = filtering_settings.split(' && ')\n",
    "\n",
    "    global Risk\n",
    "    dff2 = Risk.loc[Risk['Route'].apply(lambda x: x in values_route)\\\n",
    "                   &Risk['DepDate'].apply(lambda x: unix_time_millis(x)>=values_depdate[0] and unix_time_millis(x)<=values_depdate[1])\\\n",
    "                   &Risk['FltNum'].apply(lambda x: x in values_fltnum),:].copy()   \n",
    "    \n",
    "#     for filter in filtering_expressions:\n",
    "#         if ' eq ' in filter:\n",
    "#             col_name = filter.split(' eq ')[0].replace(\"\\\"\",\"\")\n",
    "#             filter_value = filter.split(' eq ')[1]\n",
    "#             dff2 = dff2.loc[dff2[col_name] == filter_value]\n",
    "#         if ' > ' in filter:\n",
    "#             col_name = filter.split(' > ')[0].replace(\"\\\"\",\"\")\n",
    "#             filter_value = float(filter.split(' > ')[1])\n",
    "#             dff2 = dff2.loc[dff2[col_name] > filter_value]\n",
    "#         if ' < ' in filter:\n",
    "#             col_name = filter.split(' < ')[0].replace(\"\\\"\",\"\")\n",
    "#             filter_value = float(filter.split(' < ')[1])\n",
    "#             dff2 = dff2.loc[dff2[col_name] < filter_value]\n",
    "\n",
    "    if len(sorting_settings):\n",
    "        dff2 = dff2.sort_values(\n",
    "            [col['column_id'] for col in sorting_settings],\n",
    "            ascending=[\n",
    "                col['direction'] == 'asc'\n",
    "                for col in sorting_settings\n",
    "            ],\n",
    "            inplace=False\n",
    "        )       \n",
    "\n",
    "    return dff2.iloc[\n",
    "            pagination_settings['current_page']*pagination_settings['page_size']:\n",
    "            (pagination_settings['current_page'] + 1)*pagination_settings['page_size']\n",
    "        ].to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.callback(Output('graph-bc', 'figure'),\n",
    "     #,\n",
    "     # Output('graph', 'figure')\n",
    "    [Input('dropdown_routes', 'value'),\n",
    "     Input('datetime_RangeSlider', 'value'),\n",
    "     Input('checklist_table_fltnum', 'values'),\n",
    "     Input('booking_table', 'pagination_settings'),\n",
    "     Input('booking_table', 'sort_by'),    \n",
    "     Input('booking_table', \"active_cell\")]\n",
    "    )\n",
    "def update_plot(values_route, values_depdate, values_fltnum, \n",
    "    pagination_settings, sorting_settings, active_cell):\n",
    "    \n",
    "    #filtering_expressions = filtering_settings.split(' && ')\n",
    "    \n",
    "    global Risk\n",
    "    dff2 = Risk.loc[Risk['Route'].apply(lambda x: x in values_route)\\\n",
    "                   &Risk['DepDate'].apply(lambda x: unix_time_millis(x)>=values_depdate[0] and unix_time_millis(x)<=values_depdate[1])\\\n",
    "                   &Risk['FltNum'].apply(lambda x: x in values_fltnum),:].copy()    \n",
    "    \n",
    "#     for filter in filtering_expressions:\n",
    "#         if ' eq ' in filter:\n",
    "#             col_name = filter.split(' eq ')[0].replace(\"\\\"\",\"\")\n",
    "#             filter_value = filter.split(' eq ')[1]\n",
    "#             dff2 = dff2.loc[dff2[col_name] == filter_value]\n",
    "#         if ' > ' in filter:\n",
    "#             col_name = filter.split(' > ')[0].replace(\"\\\"\",\"\")\n",
    "#             filter_value = float(filter.split(' > ')[1])\n",
    "#             dff2 = dff2.loc[dff2[col_name] > filter_value]\n",
    "#         if ' < ' in filter:\n",
    "#             col_name = filter.split(' < ')[0].replace(\"\\\"\",\"\")\n",
    "#             filter_value = float(filter.split(' < ')[1])\n",
    "#             dff2 = dff2.loc[dff2[col_name] < filter_value]\n",
    "\n",
    "    if len(sorting_settings):\n",
    "        dff2 = dff2.sort_values(\n",
    "            [col['column_id'] for col in sorting_settings],\n",
    "            ascending=[\n",
    "                col['direction'] == 'asc'\n",
    "                for col in sorting_settings\n",
    "            ],\n",
    "            inplace=False\n",
    "        )    \n",
    "\n",
    "    dff2 = dff2.iloc[\n",
    "             pagination_settings['current_page']*pagination_settings['page_size']:\n",
    "            (pagination_settings['current_page'] + 1)*pagination_settings['page_size']\n",
    "            ]              \n",
    "        \n",
    "    dff2.index=range(dff2.shape[0])     \n",
    "\n",
    "    active_row_id = active_cell['row'] if active_cell else None\n",
    "    active_column_id = active_cell['column'] if active_cell else None\n",
    "    \n",
    "    ###########################################################       \n",
    "    \n",
    "    if active_row_id is not None and (active_column_id==15 or active_column_id==16):\n",
    "        selected_route=str(dff2.loc[active_row_id,'Route'])\n",
    "        selected_depdate=str(dff2.loc[active_row_id,'DepDate'])\n",
    "        selected_fltnum=str(dff2.loc[active_row_id,'FltNum'])\n",
    "        \n",
    "        if Risk.loc[(Risk['Route']==selected_route)&(Risk['DepDate'] == selected_depdate)\\\n",
    "                                            &(Risk['FltNum'] == selected_fltnum),'Surv.'].tolist()[0]=='':\n",
    "            Risk.loc[(Risk['Route']==selected_route)&(Risk['DepDate'] == selected_depdate)\\\n",
    "            &(Risk['FltNum'] == selected_fltnum),'Surv.']='on'\n",
    "            Risk.loc[(Risk['Route']==selected_route)&(Risk['DepDate'] == selected_depdate)\\\n",
    "            &(Risk['FltNum'] == selected_fltnum),'Since']=datetime.datetime.today().strftime('%Y-%m-%d')            \n",
    "\n",
    "            Risk.loc[Risk['Surv.']=='on',['Route','DepDate','FltNum','Surv.','Since']]\\\n",
    "                                    .to_csv(path+'FrontEnd_Input_'+analyst+'/Surveillance.csv',index=False)\n",
    "        \n",
    "        else:\n",
    "            Risk.loc[(Risk['Route']==selected_route)&(Risk['DepDate'] == selected_depdate)\\\n",
    "            &(Risk['FltNum'] == selected_fltnum),'Surv.']=''\n",
    "            Risk.loc[(Risk['Route']==selected_route)&(Risk['DepDate'] == selected_depdate)\\\n",
    "            &(Risk['FltNum'] == selected_fltnum),'Since']='' \n",
    "\n",
    "            Risk.loc[Risk['Surv.']=='on',['Route','DepDate','FltNum','Surv.','Since']]\\\n",
    "                                    .to_csv(path+'FrontEnd_Input_'+analyst+'/Surveillance.csv',index=False)           \n",
    "    \n",
    "    if active_row_id is not None and active_column_id!=15 and active_column_id!=16:    \n",
    "    \n",
    "        selected_route=str(dff2.loc[active_row_id,'Route'])\n",
    "        selected_depdate=str(dff2.loc[active_row_id,'DepDate'])\n",
    "        selected_fltnum=str(dff2.loc[active_row_id,'FltNum'])\n",
    "\n",
    "#         Risk.loc[(Risk['Route']==selected_route)&(Risk['DepDate'] == selected_depdate)\\\n",
    "#         &(Risk['FltNum'] == selected_fltnum),'Steering']='checked' \n",
    "        \n",
    "        #Risk.to_csv('test.csv')\n",
    "        \n",
    "        dff_plot = Actuals.loc[(Actuals['Route']==selected_route)&(Actuals['DepDate'] == selected_depdate)\\\n",
    "        &(Actuals['FltNum'] == selected_fltnum),:].copy() \n",
    "        dff2_plot = IdealCurve.loc[(IdealCurve['Route']==selected_route)&(IdealCurve['DepDate'] == selected_depdate)\\\n",
    "        &(IdealCurve['FltNum'] == selected_fltnum),:].copy() \n",
    "        dff3_plot=Capacity.loc[(Capacity['Route']==selected_route)&(Capacity['DepDate'] == selected_depdate)\\\n",
    "            &(Capacity['FltNum'] == selected_fltnum),:].copy()\n",
    "        dff4_plot=GroupPax.loc[(GroupPax['Route']==selected_route)&(GroupPax['DepDate'] == selected_depdate)\\\n",
    "            &(GroupPax['FltNum'] == selected_fltnum),:].copy()        \n",
    "        \n",
    "        #\\\n",
    "        #    .drop_duplicates(subset=['Route','DepDate','FltNum','dtime'])\n",
    "        \n",
    "        traces = []\n",
    "        \n",
    "        for i in line_columns_Pax:\n",
    "            traces.append(go.Scatter(\n",
    "                x=dff_plot['Dprio'].tolist(),\n",
    "                y=dff_plot[i].tolist(),\n",
    "                mode = 'lines',\n",
    "                name = name_dict_Pax[i],\n",
    "                line = dict(\n",
    "                  dash = linedash_dict_Pax[i],\n",
    "                  color = linecolor_dict_Pax[i],\n",
    "                  width = 2\n",
    "               )\n",
    "            ))\n",
    "\n",
    "        for i in line_columns_Ideal:\n",
    "            traces.append(go.Scatter(\n",
    "                x=dff2_plot['Dprio'].tolist(),\n",
    "                y=dff2_plot[i].tolist(),\n",
    "                mode = 'lines',\n",
    "                name = name_dict_Ideal[i],\n",
    "                line = dict(\n",
    "                  dash = linedash_dict_Ideal[i],\n",
    "                  color = linecolor_dict_Ideal[i],\n",
    "                  width = 2\n",
    "               )\n",
    "            ))        \n",
    "\n",
    "        i='Real Cabin Capacity'\n",
    "        traces.append(go.Scatter(\n",
    "                x=dff3_plot['Dprio'].tolist(),\n",
    "                y=dff3_plot[i].tolist(),\n",
    "                mode = 'lines',\n",
    "                name = name_dict_Capacity[i],\n",
    "                line = dict(\n",
    "                  dash = linedash_dict_Capacity[i],\n",
    "                  color = linecolor_dict_Capacity[i],\n",
    "                  width = 2\n",
    "               )\n",
    "        ))\n",
    "            \n",
    "        traces.append(go.Scatter(\n",
    "                x=dff4_plot['Dprio'].tolist(),\n",
    "                y=dff4_plot['Group Pax'].tolist(),\n",
    "                fill = 'tozeroy',\n",
    "                name = 'Group_pax'\n",
    "            #,\n",
    "            #    line = dict(\n",
    "            #      dash = linedash_dict_Capacity[i],\n",
    "            #      color = linecolor_dict_Capacity[i],\n",
    "            #      width = 2\n",
    "            #   )\n",
    "        ))         \n",
    "   \n",
    "        return {'data': traces, 'layout': \n",
    "            go.Layout(title=go.layout.Title(\n",
    "            text='Dep. Date: '+selected_depdate.split(' ')[0]+' / Flt. Number: '+str(selected_fltnum),\n",
    "            xref='paper',\n",
    "            x=0.5),\n",
    "            xaxis={'title': 'Days prior to departure', 'range': [0, 365]},\n",
    "            yaxis={'title': 'Number of bookings', 'range': [0, dff3_plot['Initial Cabin Capacity'].max()+5]},\n",
    "            height=600)}\n",
    "    else:\n",
    "# #         return {'data': [], 'layout': \n",
    "# #         go.Layout(title=go.layout.Title(\n",
    "# #         text='Plot Title',\n",
    "# #         xref='paper',\n",
    "# #         x=0),\n",
    "# #         xaxis={'title': 'Days prior to departure', 'range': [0, 365]},\n",
    "# #         yaxis={'title': 'Number of bookings', 'range': [0, 70]},\n",
    "# #         height=600)}\n",
    "    \n",
    "        return {'data': []}   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.callback(Output('graph-lac', 'figure'),\n",
    "     #,\n",
    "     # Output('graph', 'figure')\n",
    "    [Input('dropdown_routes', 'value'),\n",
    "     Input('datetime_RangeSlider', 'value'),\n",
    "     Input('checklist_table_fltnum', 'values'),\n",
    "     Input('booking_table', 'pagination_settings'),\n",
    "     Input('booking_table', 'sort_by'),    \n",
    "     Input('booking_table', \"active_cell\")]\n",
    "    )\n",
    "def update_plot(values_route, values_depdate, values_fltnum, \n",
    "    pagination_settings, sorting_settings, active_cell):\n",
    "    \n",
    "    #filtering_expressions = filtering_settings.split(' && ')\n",
    "    \n",
    "    global Risk\n",
    "    dff2 = Risk.loc[Risk['Route'].apply(lambda x: x in values_route)\\\n",
    "                   &Risk['DepDate'].apply(lambda x: unix_time_millis(x)>=values_depdate[0] and unix_time_millis(x)<=values_depdate[1])\\\n",
    "                   &Risk['FltNum'].apply(lambda x: x in values_fltnum),:].copy()    \n",
    "    \n",
    "#     for filter in filtering_expressions:\n",
    "#         if ' eq ' in filter:\n",
    "#             col_name = filter.split(' eq ')[0].replace(\"\\\"\",\"\")\n",
    "#             filter_value = filter.split(' eq ')[1]\n",
    "#             dff2 = dff2.loc[dff2[col_name] == filter_value]\n",
    "#         if ' > ' in filter:\n",
    "#             col_name = filter.split(' > ')[0].replace(\"\\\"\",\"\")\n",
    "#             filter_value = float(filter.split(' > ')[1])\n",
    "#             dff2 = dff2.loc[dff2[col_name] > filter_value]\n",
    "#         if ' < ' in filter:\n",
    "#             col_name = filter.split(' < ')[0].replace(\"\\\"\",\"\")\n",
    "#             filter_value = float(filter.split(' < ')[1])\n",
    "#             dff2 = dff2.loc[dff2[col_name] < filter_value]\n",
    "\n",
    "    if len(sorting_settings):\n",
    "        dff2 = dff2.sort_values(\n",
    "            [col['column_id'] for col in sorting_settings],\n",
    "            ascending=[\n",
    "                col['direction'] == 'asc'\n",
    "                for col in sorting_settings\n",
    "            ],\n",
    "            inplace=False\n",
    "        )\n",
    "\n",
    "    dff2 = dff2.iloc[\n",
    "             pagination_settings['current_page']*pagination_settings['page_size']:\n",
    "            (pagination_settings['current_page'] + 1)*pagination_settings['page_size']\n",
    "            ]         \n",
    "\n",
    "    dff2.index=range(dff2.shape[0])     \n",
    "\n",
    "    active_row_id = active_cell['row'] if active_cell else None\n",
    "    active_column_id = active_cell['column'] if active_cell else None\n",
    "    \n",
    "    ###########################################################                 \n",
    "            \n",
    "    if active_row_id is not None and active_column_id!=15 and active_column_id!=16:    \n",
    "    \n",
    "        selected_route=str(dff2.loc[active_row_id,'Route'])\n",
    "        selected_depdate=str(dff2.loc[active_row_id,'DepDate'])\n",
    "        selected_fltnum=str(dff2.loc[active_row_id,'FltNum'])\n",
    "\n",
    "#         Risk.loc[(Risk['Route']==selected_route)&(Risk['DepDate'] == selected_depdate)\\\n",
    "#         &(Risk['FltNum'] == selected_fltnum),'Steering']='checked' \n",
    "        \n",
    "        #Risk.to_csv('test.csv')\n",
    "        \n",
    "        dff_plot = LACeco.loc[(LACeco['Route']==selected_route)&(LACeco['DepDate'] == selected_depdate)\\\n",
    "        &(LACeco['FltNum'] == selected_fltnum),:].copy()   \n",
    "        dff_plot['group']=local_groups(dff_plot['LAC_eco'])\n",
    "        dff_plot['breakgroups']=breakgroups(dff_plot['LAC_eco'].tolist())\n",
    "        \n",
    "        traces = []\n",
    "        \n",
    "        for c in dff_plot['group'].unique():\n",
    "            traces.append(go.Scatter(\n",
    "                x=dff_plot.loc[dff_plot['group']==c,'Dprio'].tolist(),\n",
    "                y=dff_plot.loc[dff_plot['group']==c,'Y'].tolist(),\n",
    "                mode = 'lines',\n",
    "                line = dict(\n",
    "                dash = 'solid',\n",
    "                color = linecolor_dict_Lac[dff_plot.loc[dff_plot['group']==c,'LAC_eco'].unique()[0]],\n",
    "                width = 2\n",
    "                    ),\n",
    "                hoverinfo = 'y'\n",
    "                ))\n",
    "        \n",
    "        for c in list(set([y for x in dff_plot['breakgroups'].tolist() for y in x if y!=0])):\n",
    "            traces.append(go.Scatter(\n",
    "                x=dff_plot.loc[dff_plot['breakgroups'].apply(lambda x: c in x),'Dprio'].tolist(),\n",
    "                y=dff_plot.loc[dff_plot['breakgroups'].apply(lambda x: c in x),'Y'].tolist(),\n",
    "                mode = 'lines',\n",
    "                line = dict(\n",
    "                dash = 'dash',\n",
    "                color = 'black',\n",
    "                width = 0.75\n",
    "                    ),\n",
    "                hoverinfo = 'none'\n",
    "                ))        \n",
    "   \n",
    "        return {'data': traces, 'layout': \n",
    "        go.Layout(title=go.layout.Title(\n",
    "        text='Dep. Date: '+selected_depdate.split(' ')[0]+' / Flt. Number: '+str(selected_fltnum),\n",
    "        xref='paper',\n",
    "        x=0.5),\n",
    "        xaxis={'title': 'Days prior to departure', 'range': [0, 365]},\n",
    "        yaxis={'title': 'LAC', 'range': [class_map['Y'].min(),class_map['Y'].max()],\n",
    "        'tickvals': class_map['Y'].tolist(), 'ticktext': class_map['LAC'].tolist()},\n",
    "        height=600,\n",
    "        showlegend=False)}\n",
    "    else:   \n",
    "        return {'data': []}     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.callback(Output('graph-bid', 'figure'),\n",
    "     #,\n",
    "     # Output('graph', 'figure')\n",
    "    [Input('dropdown_routes', 'value'),\n",
    "     Input('datetime_RangeSlider', 'value'),\n",
    "     Input('checklist_table_fltnum', 'values'),\n",
    "     Input('booking_table', 'pagination_settings'),\n",
    "     Input('booking_table', 'sort_by'),    \n",
    "     Input('booking_table', \"active_cell\")]\n",
    "    )\n",
    "def update_plot(values_route, values_depdate, values_fltnum, \n",
    "    pagination_settings, sorting_settings, active_cell):\n",
    "    \n",
    "    #filtering_expressions = filtering_settings.split(' && ')\n",
    "    \n",
    "    global Risk\n",
    "    dff2 = Risk.loc[Risk['Route'].apply(lambda x: x in values_route)\\\n",
    "                   &Risk['DepDate'].apply(lambda x: unix_time_millis(x)>=values_depdate[0] and unix_time_millis(x)<=values_depdate[1])\\\n",
    "                   &Risk['FltNum'].apply(lambda x: x in values_fltnum),:].copy()    \n",
    "    \n",
    "#     for filter in filtering_expressions:\n",
    "#         if ' eq ' in filter:\n",
    "#             col_name = filter.split(' eq ')[0].replace(\"\\\"\",\"\")\n",
    "#             filter_value = filter.split(' eq ')[1]\n",
    "#             dff2 = dff2.loc[dff2[col_name] == filter_value]\n",
    "#         if ' > ' in filter:\n",
    "#             col_name = filter.split(' > ')[0].replace(\"\\\"\",\"\")\n",
    "#             filter_value = float(filter.split(' > ')[1])\n",
    "#             dff2 = dff2.loc[dff2[col_name] > filter_value]\n",
    "#         if ' < ' in filter:\n",
    "#             col_name = filter.split(' < ')[0].replace(\"\\\"\",\"\")\n",
    "#             filter_value = float(filter.split(' < ')[1])\n",
    "#             dff2 = dff2.loc[dff2[col_name] < filter_value]\n",
    "\n",
    "    if len(sorting_settings):\n",
    "        dff2 = dff2.sort_values(\n",
    "            [col['column_id'] for col in sorting_settings],\n",
    "            ascending=[\n",
    "                col['direction'] == 'asc'\n",
    "                for col in sorting_settings\n",
    "            ],\n",
    "            inplace=False\n",
    "        )\n",
    "\n",
    "    dff2 = dff2.iloc[\n",
    "             pagination_settings['current_page']*pagination_settings['page_size']:\n",
    "            (pagination_settings['current_page'] + 1)*pagination_settings['page_size']\n",
    "            ]              \n",
    "        \n",
    "    dff2.index=range(dff2.shape[0])     \n",
    "\n",
    "    active_row_id = active_cell['row'] if active_cell else None\n",
    "    active_column_id = active_cell['column'] if active_cell else None\n",
    "    \n",
    "    ###########################################################                 \n",
    "            \n",
    "    if active_row_id is not None and active_column_id!=14 and active_column_id!=15:    \n",
    "    \n",
    "        selected_route=str(dff2.loc[active_row_id,'Route'])\n",
    "        selected_depdate=str(dff2.loc[active_row_id,'DepDate'])\n",
    "        selected_fltnum=str(dff2.loc[active_row_id,'FltNum'])\n",
    "\n",
    "#         Risk.loc[(Risk['Route']==selected_route)&(Risk['DepDate'] == selected_depdate)\\\n",
    "#         &(Risk['FltNum'] == selected_fltnum),'Steering']='checked' \n",
    "        \n",
    "        #Risk.to_csv('test.csv')\n",
    "        \n",
    "        dff_plot = BidPrice.loc[(BidPrice['Route']==selected_route)&(BidPrice['DepDate'] == selected_depdate)\\\n",
    "        &(BidPrice['FltNum'] == selected_fltnum),:].copy()   \n",
    "        \n",
    "        traces = []\n",
    "        \n",
    "        for i in line_columns_Bid:\n",
    "            traces.append(go.Scatter(\n",
    "                x=dff_plot['Dprio'].tolist(),\n",
    "                y=dff_plot[i].tolist(),\n",
    "                mode = 'lines',\n",
    "                name = name_dict_Bid[i],\n",
    "                line = dict(\n",
    "                dash = linedash_dict_Bid[i],\n",
    "                color = linecolor_dict_Bid[i],\n",
    "                width = 2\n",
    "                )\n",
    "            ))\n",
    "   \n",
    "        return {'data': traces, 'layout': \n",
    "        go.Layout(title=go.layout.Title(\n",
    "        text='Dep. Date: '+selected_depdate.split(' ')[0]+' / Flt. Number: '+str(selected_fltnum),\n",
    "        xref='paper',\n",
    "        x=0.5),\n",
    "        xaxis={'title': 'Days prior to departure', 'range': [0, 365]},\n",
    "        yaxis={'title': 'Bid Price', 'range': [0,dff_plot['BidPrice_eco'].max()+5]},\n",
    "        height=600)}\n",
    "    else:   \n",
    "        return {'data': []}     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.callback(Output('graph-classbook', 'figure'),\n",
    "     #,\n",
    "     # Output('graph', 'figure')\n",
    "    [Input('dropdown_routes', 'value'),\n",
    "     Input('datetime_RangeSlider', 'value'),\n",
    "     Input('checklist_table_fltnum', 'values'),\n",
    "     Input('booking_table', 'pagination_settings'),\n",
    "     Input('booking_table', 'sort_by'),    \n",
    "     Input('booking_table', \"active_cell\")]\n",
    "    )\n",
    "def update_plot(values_route, values_depdate, values_fltnum, \n",
    "    pagination_settings, sorting_settings, active_cell):\n",
    "    \n",
    "    #filtering_expressions = filtering_settings.split(' && ')\n",
    "    \n",
    "    global Risk\n",
    "    dff2 = Risk.loc[Risk['Route'].apply(lambda x: x in values_route)\\\n",
    "                   &Risk['DepDate'].apply(lambda x: unix_time_millis(x)>=values_depdate[0] and unix_time_millis(x)<=values_depdate[1])\\\n",
    "                   &Risk['FltNum'].apply(lambda x: x in values_fltnum),:].copy()    \n",
    "    \n",
    "#     for filter in filtering_expressions:\n",
    "#         if ' eq ' in filter:\n",
    "#             col_name = filter.split(' eq ')[0].replace(\"\\\"\",\"\")\n",
    "#             filter_value = filter.split(' eq ')[1]\n",
    "#             dff2 = dff2.loc[dff2[col_name] == filter_value]\n",
    "#         if ' > ' in filter:\n",
    "#             col_name = filter.split(' > ')[0].replace(\"\\\"\",\"\")\n",
    "#             filter_value = float(filter.split(' > ')[1])\n",
    "#             dff2 = dff2.loc[dff2[col_name] > filter_value]\n",
    "#         if ' < ' in filter:\n",
    "#             col_name = filter.split(' < ')[0].replace(\"\\\"\",\"\")\n",
    "#             filter_value = float(filter.split(' < ')[1])\n",
    "#             dff2 = dff2.loc[dff2[col_name] < filter_value]\n",
    "\n",
    "    if len(sorting_settings):\n",
    "        dff2 = dff2.sort_values(\n",
    "            [col['column_id'] for col in sorting_settings],\n",
    "            ascending=[\n",
    "                col['direction'] == 'asc'\n",
    "                for col in sorting_settings\n",
    "            ],\n",
    "            inplace=False\n",
    "        )\n",
    "\n",
    "    dff2 = dff2.iloc[\n",
    "             pagination_settings['current_page']*pagination_settings['page_size']:\n",
    "            (pagination_settings['current_page'] + 1)*pagination_settings['page_size']\n",
    "            ]              \n",
    "        \n",
    "    dff2.index=range(dff2.shape[0])     \n",
    "\n",
    "    active_row_id = active_cell['row'] if active_cell else None\n",
    "    active_column_id = active_cell['column'] if active_cell else None\n",
    "    \n",
    "    ###########################################################                 \n",
    "            \n",
    "    if active_row_id is not None and active_column_id!=14 and active_column_id!=15:    \n",
    "    \n",
    "        selected_route=str(dff2.loc[active_row_id,'Route'])\n",
    "        selected_depdate=str(dff2.loc[active_row_id,'DepDate'])\n",
    "        selected_fltnum=str(dff2.loc[active_row_id,'FltNum'])\n",
    "\n",
    "#         Risk.loc[(Risk['Route']==selected_route)&(Risk['DepDate'] == selected_depdate)\\\n",
    "#         &(Risk['FltNum'] == selected_fltnum),'Steering']='checked' \n",
    "        \n",
    "        #Risk.to_csv('test.csv')\n",
    "        \n",
    "        dff_plot = ClassBooking.loc[(ClassBooking['Route']==selected_route)&(ClassBooking['DepDate'] == selected_depdate)\\\n",
    "        &(ClassBooking['FltNum'] == selected_fltnum),:].copy()   \n",
    "\n",
    "        traces = []\n",
    "        \n",
    "        for i in line_columns_ClassBooking:\n",
    "            traces.append(go.Scatter(\n",
    "                x=dff_plot['Dprio'].tolist(),\n",
    "                y=dff_plot[i].tolist(),\n",
    "                mode = 'lines',\n",
    "                name = name_dict_ClassBooking[i],\n",
    "                line = dict(\n",
    "                dash = linedash_dict_ClassBooking[i],\n",
    "                color = linecolor_dict_ClassBooking[i],\n",
    "                width = 2\n",
    "                )\n",
    "            ))\n",
    "   \n",
    "        return {'data': traces, 'layout': \n",
    "        go.Layout(title=go.layout.Title(\n",
    "        text='Dep. Date: '+selected_depdate.split(' ')[0]+' / Flt. Number: '+str(selected_fltnum),\n",
    "        xref='paper',\n",
    "        x=0.5),\n",
    "        xaxis={'title': 'Days prior to departure', 'range': [0, 365]},\n",
    "        yaxis={'title': 'Bookings by Class', 'range': [0,100]},\n",
    "        height=600)}\n",
    "    else:   \n",
    "        return {'data': []}     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_server(self,\n",
    "#                port=8050,\n",
    "#                debug=True,\n",
    "#                threaded=True,\n",
    "#                **flask_run_options):\n",
    "#     self.server.run(port=port, debug=debug, **flask_run_options)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://10.0.0.8:3998/ (Press CTRL+C to quit)\n",
      "172.27.2.93 - - [14/Jun/2019 13:44:05] \"GET / HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:44:05] \"GET /_dash-dependencies HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:44:05] \"GET /_dash-layout HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:44:06] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:44:06] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:44:06] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:44:06] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:44:06] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:44:06] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:44:06] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:44:06] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:44:07] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:44:08] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:44:09] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:44:11] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:44:12] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:44:13] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:44:15] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:44:15] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:44:16] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:44:17] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:44:17] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:44:17] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:44:17] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:44:18] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:44:20] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:44:21] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:44:22] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:44:23] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:44:24] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:44:25] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:44:26] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:44:28] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:44:28] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:44:28] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:44:30] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:44:30] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:44:31] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:44:32] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:44:32] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:44:32] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:44:32] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:44:33] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:44:34] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:44:36] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:44:36] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:44:36] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:44:36] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:44:36] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:44:36] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:44:37] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:44:38] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:44:39] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:44:40] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:44:40] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:44:42] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:44:44] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:44:44] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:44:44] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:44:45] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:44:45] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:44:45] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:44:45] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:44:46] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:44:46] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:44:47] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:44:47] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:44:47] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:44:48] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:44:48] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:44:49] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:44:50] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:44:51] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:44:51] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:44:52] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:44:52] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:44:53] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:44:55] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:44:56] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:44:57] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:44:58] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:45:00] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:45:01] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:45:02] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:45:03] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:45:05] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:45:06] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:45:07] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:45:08] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:45:10] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:45:11] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:45:12] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:45:13] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:45:15] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:45:16] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:45:17] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:45:18] \"POST /_dash-update-component HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "172.27.2.93 - - [14/Jun/2019 13:45:20] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:45:21] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:45:22] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:45:23] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:45:25] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:45:26] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:45:27] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:45:28] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:45:30] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:45:31] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:45:32] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:45:33] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:45:35] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:45:36] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:45:37] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:45:38] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:45:40] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:45:41] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:45:42] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:45:43] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:45:45] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:45:46] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:45:47] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:45:48] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:45:51] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:45:56] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:45:59] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:45:59] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:46:01] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:46:02] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:46:03] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:46:03] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:46:03] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:46:03] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:46:03] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:46:03] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:46:04] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:46:06] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:46:06] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:46:07] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:46:07] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:46:09] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:46:09] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:46:09] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:46:10] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:46:11] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:46:13] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:46:13] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:46:14] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:46:14] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:46:14] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:46:14] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:46:14] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:46:16] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:46:16] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:46:18] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:46:18] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:46:18] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:46:18] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:46:21] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:46:21] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:46:23] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:46:23] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:46:24] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:46:24] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:46:25] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:46:26] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:46:27] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:46:27] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:46:29] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:46:30] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:46:31] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:46:32] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:46:32] \"POST /_dash-update-component HTTP/1.1\" 200 -\n",
      "172.27.2.93 - - [14/Jun/2019 13:46:32] \"POST /_dash-update-component HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=False,host='10.0.0.8',port=port[analyst])\n",
    "    #app.run_server(debug=False,host='localhost',port=4000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
