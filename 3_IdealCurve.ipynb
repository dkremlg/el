{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pandas import Series\n",
    "from pandas import DataFrame\n",
    "\n",
    "from scipy.stats import poisson\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "route='LUX-CPH'\n",
    "risk_spill=0.8\n",
    "risk_spoil=risk_spill\n",
    "unique_identifier=['DepDate','FltNum','dtime']\n",
    "cluster_variables=['dday','dtime','Direction','month']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Determine downweight factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_datadriven=pd.read_csv('~/Data/Intermediate_Output/R_Training_Pax.csv')\n",
    "#C_datadriven=pd.read_csv('R_Training_Pax.csv')\n",
    "C_datadriven=C_datadriven.groupby(cluster_variables)['NumPax'].sum().reset_index()\n",
    "C_datadriven=C_datadriven.groupby(cluster_variables)['NumPax'].max().reset_index().rename(columns={'NumPax': 'downweight'})\n",
    "C_datadriven['downweight']=C_datadriven['downweight'].astype('float')/0.8\n",
    "C_datadriven['downweight']=C_datadriven['downweight'].apply(lambda x: 0.8 if x>0.8 else x)\n",
    "C_datadriven['downweight']=0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C_datadriven.loc[C_datadriven['month']==5,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import to total capacity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "TotalCap=pd.read_csv('~/Data/FrontEnd_Input/Capacity_forPlots_'+route+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "Prediction=pd.read_csv('~/Data/Intermediate_Output/R_Output_Test_Pax.csv',sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Associate downweight factor and cabin capacity to prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "Prediction=Prediction.merge(C_datadriven,on=cluster_variables,how='left')\n",
    "Prediction['downweight']=Prediction['downweight'].apply(lambda x: 0.8 if pd.isnull(x) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "deptime=[str(x/60).split('.')[0]+':'+str(round(float('0.'+str(x/60).split('.')[1])*60)) for x in Prediction['dtime'].unique()]\n",
    "deptime=[x+'0' if len(x.split(':')[1])==1 else x for x in deptime]\n",
    "deptime=['0'+x if len(x.split(':')[0])==1 else x for x in deptime]\n",
    "\n",
    "Map_DepTime=DataFrame([Prediction['dtime'].unique(),[x+'0' if len(x.split(':')[1])==1 else x for x in deptime]]).transpose()\n",
    "Map_DepTime.columns=['dtime','deptime']\n",
    "Map_DepTime['dtime']=Map_DepTime['dtime'].astype('int')\n",
    "\n",
    "Prediction=Prediction.merge(Map_DepTime,on='dtime')\n",
    "Prediction['dtime']=Prediction['deptime']\n",
    "Prediction=Prediction[[x for x in Prediction.columns if x!='deptime']]\n",
    "\n",
    "Prediction=Prediction.merge(TotalCap[unique_identifier+['Dprio','Cabin Capacity']],\n",
    "on=unique_identifier+['Dprio'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(330808, 13)"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "IdealCurve=Prediction[unique_identifier+['Dprio','forecast_bookings','Cabin Capacity','downweight']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "IdealCurve=IdealCurve.merge(IdealCurve.groupby(unique_identifier)['forecast_bookings'].sum().reset_index()\\\n",
    ".rename(columns={'forecast_bookings': 'forecast_bookings_sum'}),on=['DepDate','FltNum','dtime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "IdealCurve['forecast_bookings']=IdealCurve['forecast_bookings']/IdealCurve['forecast_bookings_sum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "IdealCurve=IdealCurve[[x for x in IdealCurve.columns if x!='forecast_bookings_sum']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "IdealCurve['lambda_100']=IdealCurve['Cabin Capacity']*IdealCurve['forecast_bookings']\n",
    "IdealCurve['lambda_80']=IdealCurve['Cabin Capacity']*IdealCurve['downweight']*IdealCurve['forecast_bookings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "IdealCurve=IdealCurve[unique_identifier+['Dprio']+[x for x in IdealCurve.columns if 'lambda' in x]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "IdealCurve['Dprio']=-IdealCurve['Dprio']\n",
    "IdealCurve=IdealCurve.set_index(['Dprio']+unique_identifier)\n",
    "\n",
    "IdealCurve_cumul_100=IdealCurve.groupby(level=[x for x in range(len(unique_identifier)+1)]).sum()\\\n",
    ".groupby(level=[x for x in range(1,len(unique_identifier)+1)])['lambda_100'].cumsum().reset_index().rename(columns={'lambda_100': 'lambda_100_cumsum'})\n",
    "IdealCurve_cumul_100['Dprio']=-IdealCurve_cumul_100['Dprio']\n",
    "\n",
    "IdealCurve_cumul_80=IdealCurve.groupby(level=[x for x in range(len(unique_identifier)+1)]).sum()\\\n",
    ".groupby(level=[x for x in range(1,len(unique_identifier)+1)])['lambda_80'].cumsum().reset_index().rename(columns={'lambda_80': 'lambda_80_cumsum'})\n",
    "IdealCurve_cumul_80['Dprio']=-IdealCurve_cumul_80['Dprio']\n",
    "\n",
    "IdealCurve=IdealCurve.reset_index()\n",
    "IdealCurve['Dprio']=-IdealCurve['Dprio']\n",
    "\n",
    "IdealCurve=IdealCurve.set_index(['Dprio']+unique_identifier)\n",
    "\n",
    "IdealCurve_cond_100=IdealCurve.groupby(level=[x for x in range(len(unique_identifier)+1)]).sum()\\\n",
    ".groupby(level=[x for x in range(1,len(unique_identifier)+1)])['lambda_100'].cumsum().reset_index().rename(columns={'lambda_100': 'lambda_100_cond'})\n",
    "\n",
    "IdealCurve_cond_80=IdealCurve.groupby(level=[x for x in range(len(unique_identifier)+1)]).sum()\\\n",
    ".groupby(level=[x for x in range(1,len(unique_identifier)+1)])['lambda_80'].cumsum().reset_index().rename(columns={'lambda_80': 'lambda_80_cond'})\n",
    "\n",
    "IdealCurve=IdealCurve.reset_index()\n",
    "\n",
    "IdealCurve_cumul_100=IdealCurve_cumul_100.sort_values(by=['Dprio']+unique_identifier)\n",
    "IdealCurve_cumul_80=IdealCurve_cumul_80.sort_values(by=['Dprio']+unique_identifier)\n",
    "IdealCurve_cond_100=IdealCurve_cond_100.sort_values(by=['Dprio']+unique_identifier)\n",
    "IdealCurve_cond_100['thres_100']=poisson.ppf(1-risk_spoil,IdealCurve_cond_100['lambda_100_cond'])\n",
    "IdealCurve_cond_80=IdealCurve_cond_80.sort_values(by=['Dprio']+unique_identifier)\n",
    "IdealCurve_cond_80['thres_80']=poisson.ppf(risk_spoil,IdealCurve_cond_80['lambda_80_cond'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "IdealCurve_cond_100=IdealCurve_cond_100\\\n",
    ".merge(Prediction[['Dprio']+unique_identifier+['Cabin Capacity']],on=['Dprio']+unique_identifier)\n",
    "\n",
    "IdealCurve_cond_80=IdealCurve_cond_80\\\n",
    ".merge(Prediction[['Dprio']+unique_identifier+['Cabin Capacity','downweight']],on=['Dprio']+unique_identifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "IdealCurve_cond_100['Ideal_upper']=IdealCurve_cond_100['Cabin Capacity']-IdealCurve_cond_100['thres_100']\n",
    "IdealCurve_cond_100['Ideal_upper']=IdealCurve_cond_100[['Ideal_upper','Cabin Capacity']].apply(lambda x: x[1] if x[0]>x[1] else x[0],axis=1)\n",
    "IdealCurve_cond_80['Ideal_lower']=IdealCurve_cond_80['Cabin Capacity']*IdealCurve_cond_80['downweight']-IdealCurve_cond_80['thres_80']\n",
    "IdealCurve_cond_80['Ideal_lower']=IdealCurve_cond_80['Ideal_lower'].apply(lambda x: 0 if x<0 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "IdealCurve=IdealCurve_cumul_100.merge(IdealCurve_cumul_80,on=['Dprio']+unique_identifier)\\\n",
    ".merge(IdealCurve_cond_80[['Dprio']+unique_identifier+['Ideal_lower']],on=['Dprio']+unique_identifier)\\\n",
    ".merge(IdealCurve_cond_100[['Dprio']+unique_identifier+['Ideal_upper']],on=['Dprio']+unique_identifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "IdealCurve=IdealCurve[['Dprio']+unique_identifier+['Ideal_lower','lambda_80_cumsum','lambda_100_cumsum','Ideal_upper']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "IdealCurve.columns=['Dprio']+unique_identifier+['Ramp-up frontier','Ideal curve (80% LF)','Ideal curve (100% LF)','Phase-down frontier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "IdealCurve.to_csv('~/Data/Intermediate_Output/IdealCurve.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Risk and Actual Bookings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "Risk=Prediction[['Dprio']+unique_identifier+['NumPax']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mapping_StrToDt=pd.concat([Series(Risk['DepDate'].unique()),\n",
    "Series([pd.to_datetime(x) for x in Risk['DepDate'].unique()])],axis=1)\n",
    "Mapping_StrToDt.columns=['DepDate','DepDate_new']\n",
    "Risk=Risk.merge(Mapping_StrToDt,on='DepDate')\n",
    "Risk['DepDate']=Risk['DepDate_new']\n",
    "Risk=Risk[[x for x in Risk.columns if x!='DepDate_new']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "Risk['Dprio']=-Risk['Dprio']\n",
    "Risk=Risk.set_index(['Dprio']+unique_identifier)\n",
    "\n",
    "Risk=Risk.groupby(level=[x for x in range(len(unique_identifier)+1)]).sum()\\\n",
    ".groupby(level=[x for x in range(1,len(unique_identifier)+1)])['NumPax'].cumsum().reset_index()\\\n",
    ".rename(columns={'NumPax': 'NumPax_cumsum'})\n",
    "\n",
    "Risk['Dprio']=-Risk['Dprio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "Risk['IssueDate']=Risk['DepDate']-Risk['Dprio'].apply(lambda x: datetime.timedelta(x-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "Actuals=Risk.loc[Risk['IssueDate']<=pd.to_datetime(datetime.datetime.today().strftime('%Y-%m-%d')),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "Actuals=Actuals[[x for x in Actuals.columns if x!='IssueDate']]\n",
    "Actuals=Actuals.rename(columns={'NumPax_cumsum': 'Actual Bookings'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "Risk=Risk.loc[Risk['IssueDate']==pd.to_datetime(datetime.datetime.today().strftime('%Y-%m-%d')),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "Risk=Risk[[x for x in Risk.columns if x!='IssueDate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "Risk['DepDate']=Risk['DepDate'].apply(lambda x: str(x).split(' ')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "Risk=Risk.merge(Prediction[['Dprio']+unique_identifier+['Cabin Capacity','downweight']],\n",
    "               on=['Dprio']+unique_identifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "Risk=Risk.merge(IdealCurve_cond_100[['Dprio']+unique_identifier+['lambda_100_cond']],on=['Dprio']+unique_identifier)\\\n",
    ".merge(IdealCurve_cond_80[['Dprio']+unique_identifier+['lambda_80_cond']],on=['Dprio']+unique_identifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "Risk['SpillageRisk']=1-poisson.cdf(Risk['Cabin Capacity']-Risk['NumPax_cumsum'],Risk['lambda_100_cond'])\n",
    "Risk['SpoilageRisk']=poisson.cdf(Risk['Cabin Capacity']*Risk['downweight']-Risk['NumPax_cumsum'],Risk['lambda_80_cond'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "Risk=Risk.merge(IdealCurve[['Dprio']+unique_identifier+['Ramp-up frontier','Phase-down frontier']],\n",
    "          on=['Dprio']+unique_identifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "Risk['Intensity_downweighted']=Risk['NumPax_cumsum']-Risk['Ramp-up frontier']\n",
    "Risk['Intensity_full']=Risk['NumPax_cumsum']-Risk['Phase-down frontier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "Risk=Risk[['DepDate','FltNum','dtime','SpoilageRisk','Intensity_downweighted','Intensity_full','SpillageRisk']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "Risk=Risk.merge(Prediction[unique_identifier+['Direction','month','dday']].drop_duplicates(subset=unique_identifier),on=unique_identifier)\n",
    "Risk['Route']=route\n",
    "\n",
    "MonthMapping=DataFrame([[x for x in range(1,13)],['January','February','March','April','May','June','July','August',\n",
    "                'September','October','November','December']]).transpose()\n",
    "MonthMapping.columns=['month','Month']\n",
    "MonthMapping['month']=MonthMapping['month'].astype('int') \n",
    "Risk=Risk.merge(MonthMapping,on='month')\n",
    "Risk['month']=Risk['Month']\n",
    "Risk=Risk[[x for x in Risk.columns if x!='Month']]\n",
    "\n",
    "Risk=Risk[['Route','DepDate', 'FltNum', 'dtime', 'Direction', 'month', 'dday',\n",
    "       'SpoilageRisk', 'Intensity_downweighted', 'Intensity_full',\n",
    "       'SpillageRisk']]\n",
    "\n",
    "Risk=Risk.sort_values(by=['DepDate', 'FltNum', 'dtime', 'Direction'])\n",
    "\n",
    "Risk.to_csv('~/Data/FrontEnd_Input/Risk_'+route+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "Actuals['DepDate']=Actuals['DepDate'].apply(lambda x: str(x).split(' ')[0])\n",
    "\n",
    "Actuals=Actuals.merge(Prediction[unique_identifier+['Direction','month','dday']].drop_duplicates(subset=unique_identifier),\n",
    "on=unique_identifier)\n",
    "Actuals['Route']=route\n",
    "\n",
    "Actuals=Actuals[['Route','DepDate', 'FltNum', 'dtime', 'Direction', 'month', 'dday', 'Dprio','Actual Bookings']]\n",
    "\n",
    "Actuals['Actual Bookings']=Actuals['Actual Bookings'].apply(lambda x: x if x>=0 else 0)\n",
    "\n",
    "Actuals.to_csv('~/Data/FrontEnd_Input/Actuals_'+route+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "IdealCurve=IdealCurve.merge(Prediction[unique_identifier+['Direction','month','dday']].drop_duplicates(subset=unique_identifier),\n",
    "on=unique_identifier)\n",
    "\n",
    "IdealCurve['Route']=route\n",
    "\n",
    "IdealCurve=IdealCurve[['Route','DepDate', 'FltNum', 'dtime', 'Direction', 'month', 'dday', 'Dprio',\n",
    "'Ramp-up frontier','Ideal curve (80% LF)','Ideal curve (100% LF)','Phase-down frontier']]\n",
    "\n",
    "IdealCurve.to_csv('~/Data/FrontEnd_Input/IdealCurve_'+route+'.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
